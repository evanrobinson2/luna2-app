import logging
from typing import Dict, Any, List
import time

# Adjust these imports to match your actual module paths
from luna.luna_personas import get_system_prompt_by_localpart 
from luna import bot_messages_store2


logger = logging.getLogger(__name__)

def build_context(
    bot_localpart: str,
    room_id: str,
    config: Dict[str, Any] | None = None
) -> List[Dict[str, str]]:
    """
    Builds a GPT-style conversation array for this bot in the given room.

    :param bot_localpart: "inky", "blended_malt", etc.
    :param room_id: The Matrix room ID where the conversation took place.
    :param config: Optional dict with instructions on how many messages to fetch,
                   whether to do advanced summarization, etc.
    :return: A list of dicts in GPT 'messages' format. Example:
             [
               {"role": "system", "content": "System instructions..."},
               {"role": "user",   "content": "Hello bot!"},
               {"role": "assistant", "content": "Hi user!"}
             ]
    """
    if config is None:
        config = {}

    # 1) Get the system prompt from personas
    system_prompt = get_system_prompt_by_localpart(bot_localpart)
    if not system_prompt:
        system_prompt = (
            "You are a helpful assistant. Your persona data is missing, "
            "so just be polite and friendly."
        )

    # 2) Decide how many messages to fetch (e.g. default to last 10)
    max_history = config.get("max_history", 10)

    # 3) Query the store for recent messages for this bot
    all_msgs = bot_messages_store2.get_messages_for_bot(bot_localpart)

    # Filter by the specific room if you want only that conversation
    relevant_msgs = [m for m in all_msgs if m["room_id"] == room_id]

    # Sort ascending by timestamp (if not already)
    relevant_msgs.sort(key=lambda x: x["timestamp"], reverse=False)

    # Take the last N
    truncated = relevant_msgs[-max_history:]

    # 4) Build the GPT 'messages' array
    #    - Start with system prompt
    conversation = [{"role": "system", "content": system_prompt}]

    #    - Then convert each inbound/outbound to either user or assistant
    #      role, so GPT knows who said what.
    #    - We'll treat "sender == @bot:localhost" as assistant;
    #      everything else as user. You can refine if needed.
    bot_full_id = f"@{bot_localpart}:localhost"

    for msg in truncated:
        if msg["sender"] == bot_full_id:
            # Bot's own message => assistant role
            conversation.append({
                "role": "assistant",
                "content": msg["body"]
            })
        else:
            # Another user => user role
            conversation.append({
                "role": "user",
                "content": msg["body"]
            })

    logger.debug(
        f"[build_context] Assembled {len(conversation)} messages for '{bot_localpart}' in {room_id}."
    )

    return conversation
