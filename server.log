2025-01-05 03:54:25,626 [ERROR] asyncio: Task was destroyed but it is pending!
task: <Task pending name='Task-21056' coro=<AsyncClient.sync() done, defined at /Users/evanrobinson/Documents/Luna2/luna/.venv/lib/python3.13/site-packages/nio/client/base_client.py:113> wait_for=<Future pending cb=[Task.task_wakeup()]> cb=[_AsCompletedIterator._handle_completion()]>
2025-01-05 03:54:38,559 [DEBUG] __main__: Added file handler to root logger. Logging to 'server.log' at DEBUG level.
2025-01-05 03:54:38,559 [DEBUG] __main__: Exiting configure_logging function.
2025-01-05 03:54:38,559 [DEBUG] __main__: Logging configuration complete.
2025-01-05 03:54:38,559 [DEBUG] __main__: Creating a new asyncio event loop.
2025-01-05 03:54:38,559 [DEBUG] asyncio: Using selector: KqueueSelector
2025-01-05 03:54:38,560 [DEBUG] __main__: Set this new loop as the default event loop for the current thread.
2025-01-05 03:54:38,560 [DEBUG] __main__: Stored reference to the new loop in MAIN_LOOP.
2025-01-05 03:54:38,560 [DEBUG] __main__: Entering start_console_thread function.
2025-01-05 03:54:38,560 [INFO] __main__: Console thread started successfully.
2025-01-05 03:54:38,560 [DEBUG] __main__: Exiting start_console_thread function.
2025-01-05 03:54:38,560 [DEBUG] __main__: Console thread has been initiated. Returning to main thread.
2025-01-05 03:54:38,560 [INFO] __main__: Starting main_logic coroutine.
2025-01-05 03:54:38,560 [DEBUG] __main__: Entering main_logic function...
2025-01-05 03:54:38,560 [DEBUG] __main__: Attempting to load or log in the client.
2025-01-05 03:54:38,661 [DEBUG] src.luna_functions: Found director_token.json, attempting token-based login.
2025-01-05 03:54:38,662 [DEBUG] src.luna_functions: Loading client with saved token credentials.
2025-01-05 03:54:38,662 [INFO] src.luna_functions: Using saved token for user @luna:localhost.
2025-01-05 03:54:38,662 [DEBUG] __main__: Client obtained. Storing reference to DIRECTOR_CLIENT in src.luna_functions.
2025-01-05 03:54:38,662 [DEBUG] __main__: Callbacks registered successfully.
2025-01-05 03:54:38,662 [DEBUG] __main__: Starting sync_forever loop. Awaiting new events with timeout=30000.
2025-01-05 03:54:38,665 [WARNING] nio.client.async_client: Timed out, sleeping for 0s
2025-01-05 03:54:38,666 [WARNING] nio.client.async_client: Timed out, sleeping for 0s
2025-01-05 03:54:38,871 [WARNING] nio.client.async_client: Timed out, sleeping for 0s
2025-01-05 03:54:39,274 [WARNING] nio.client.async_client: Timed out, sleeping for 0s
2025-01-05 03:54:40,078 [WARNING] nio.client.async_client: Timed out, sleeping for 1s
2025-01-05 03:54:41,684 [WARNING] nio.client.async_client: Timed out, sleeping for 3s
2025-01-05 03:54:44,889 [WARNING] nio.client.async_client: Timed out, sleeping for 6s
2025-01-05 03:54:51,293 [WARNING] nio.client.async_client: Timed out, sleeping for 12s
2025-01-05 03:54:52,120 [WARNING] __main__: KeyboardInterrupt received. Shutting down Director.
2025-01-05 03:54:52,120 [DEBUG] __main__: Preparing to close the event loop.
2025-01-05 03:54:52,121 [INFO] __main__: Event loop closed. Exiting main function.
2025-01-05 03:54:55,139 [DEBUG] __main__: Added file handler to root logger. Logging to 'server.log' at DEBUG level.
2025-01-05 03:54:55,139 [DEBUG] __main__: Exiting configure_logging function.
2025-01-05 03:54:55,139 [DEBUG] __main__: Logging configuration complete.
2025-01-05 03:54:55,139 [DEBUG] __main__: Creating a new asyncio event loop.
2025-01-05 03:54:55,139 [DEBUG] asyncio: Using selector: KqueueSelector
2025-01-05 03:54:55,139 [DEBUG] __main__: Set this new loop as the default event loop for the current thread.
2025-01-05 03:54:55,139 [DEBUG] __main__: Stored reference to the new loop in MAIN_LOOP.
2025-01-05 03:54:55,139 [DEBUG] __main__: Entering start_console_thread function.
2025-01-05 03:54:55,139 [INFO] __main__: Console thread started successfully.
2025-01-05 03:54:55,139 [DEBUG] __main__: Exiting start_console_thread function.
2025-01-05 03:54:55,139 [DEBUG] __main__: Console thread has been initiated. Returning to main thread.
2025-01-05 03:54:55,139 [INFO] __main__: Starting main_logic coroutine.
2025-01-05 03:54:55,139 [DEBUG] __main__: Entering main_logic function...
2025-01-05 03:54:55,139 [DEBUG] __main__: Attempting to load or log in the client.
2025-01-05 03:54:55,241 [DEBUG] src.luna_functions: Found director_token.json, attempting token-based login.
2025-01-05 03:54:55,242 [DEBUG] src.luna_functions: Loading client with saved token credentials.
2025-01-05 03:54:55,242 [INFO] src.luna_functions: Using saved token for user @luna:localhost.
2025-01-05 03:54:55,242 [DEBUG] __main__: Client obtained. Storing reference to DIRECTOR_CLIENT in src.luna_functions.
2025-01-05 03:54:55,242 [DEBUG] __main__: Callbacks registered successfully.
2025-01-05 03:54:55,242 [DEBUG] __main__: Starting sync_forever loop. Awaiting new events with timeout=30000.
2025-01-05 03:54:55,246 [WARNING] nio.client.async_client: Timed out, sleeping for 0s
2025-01-05 03:54:55,247 [WARNING] nio.client.async_client: Timed out, sleeping for 0s
2025-01-05 03:54:55,454 [WARNING] nio.client.async_client: Timed out, sleeping for 0s
2025-01-05 03:54:55,858 [WARNING] nio.client.async_client: Timed out, sleeping for 0s
2025-01-05 03:54:56,663 [WARNING] nio.client.async_client: Timed out, sleeping for 1s
2025-01-05 03:54:58,265 [WARNING] nio.client.async_client: Timed out, sleeping for 3s
2025-01-05 03:55:01,467 [WARNING] nio.client.async_client: Timed out, sleeping for 6s
2025-01-05 03:55:07,871 [WARNING] nio.client.async_client: Timed out, sleeping for 12s
2025-01-05 03:55:21,961 [WARNING] nio.client.async_client: Timed out, sleeping for 0s
2025-01-05 03:55:21,963 [WARNING] nio.client.async_client: Timed out, sleeping for 0s
2025-01-05 03:55:22,165 [WARNING] nio.client.async_client: Timed out, sleeping for 0s
2025-01-05 03:55:22,577 [WARNING] nio.client.async_client: Timed out, sleeping for 0s
2025-01-05 03:55:23,381 [WARNING] nio.client.async_client: Timed out, sleeping for 1s
2025-01-05 03:55:24,984 [WARNING] nio.client.async_client: Timed out, sleeping for 3s
2025-01-05 03:55:28,187 [WARNING] nio.client.async_client: Timed out, sleeping for 6s
2025-01-05 03:55:34,593 [WARNING] nio.client.async_client: Timed out, sleeping for 12s
2025-01-05 03:55:47,398 [WARNING] nio.client.async_client: Timed out, sleeping for 25s
2025-01-05 03:56:13,005 [WARNING] nio.client.async_client: Timed out, sleeping for 51s
2025-01-05 03:57:04,215 [WARNING] nio.client.async_client: Timed out, sleeping for 60s
2025-01-05 03:57:12,755 [INFO] src.console_functions: Console received 'exit' command; calling sys.exit(0).
2025-01-05 03:57:14,895 [WARNING] __main__: KeyboardInterrupt received. Shutting down Director.
2025-01-05 03:57:14,896 [DEBUG] __main__: Preparing to close the event loop.
2025-01-05 03:57:14,896 [INFO] __main__: Event loop closed. Exiting main function.
2025-01-05 03:57:14,923 [ERROR] asyncio: Task was destroyed but it is pending!
task: <Task pending name='Task-974' coro=<AsyncClient.sync() running at /Users/evanrobinson/Documents/Luna2/luna/.venv/lib/python3.13/site-packages/nio/client/base_client.py:116> wait_for=<Future pending cb=[Task.task_wakeup()]> cb=[_AsCompletedIterator._handle_completion()]>
2025-01-05 03:57:14,944 [ERROR] asyncio: Unclosed client session
client_session: <aiohttp.client.ClientSession object at 0x1074992b0>
2025-01-05 03:57:16,785 [DEBUG] __main__: Added file handler to root logger. Logging to 'server.log' at DEBUG level.
2025-01-05 03:57:16,785 [DEBUG] __main__: Exiting configure_logging function.
2025-01-05 03:57:16,786 [DEBUG] __main__: Logging configuration complete.
2025-01-05 03:57:16,786 [DEBUG] __main__: Creating a new asyncio event loop.
2025-01-05 03:57:16,786 [DEBUG] asyncio: Using selector: KqueueSelector
2025-01-05 03:57:16,786 [DEBUG] __main__: Set this new loop as the default event loop for the current thread.
2025-01-05 03:57:16,786 [DEBUG] __main__: Stored reference to the new loop in MAIN_LOOP.
2025-01-05 03:57:16,786 [DEBUG] __main__: Entering start_console_thread function.
2025-01-05 03:57:16,786 [INFO] __main__: Console thread started successfully.
2025-01-05 03:57:16,786 [DEBUG] __main__: Exiting start_console_thread function.
2025-01-05 03:57:16,786 [DEBUG] __main__: Console thread has been initiated. Returning to main thread.
2025-01-05 03:57:16,786 [INFO] __main__: Starting main_logic coroutine.
2025-01-05 03:57:16,786 [DEBUG] __main__: Entering main_logic function...
2025-01-05 03:57:16,786 [DEBUG] __main__: Attempting to load or log in the client.
2025-01-05 03:57:16,887 [DEBUG] src.luna_functions: No valid token found, attempting normal password login.
2025-01-05 03:57:16,890 [WARNING] nio.client.async_client: Timed out, sleeping for 0s
2025-01-05 03:57:16,891 [WARNING] nio.client.async_client: Timed out, sleeping for 0s
2025-01-05 03:57:17,101 [WARNING] nio.client.async_client: Timed out, sleeping for 0s
2025-01-05 03:57:17,504 [WARNING] nio.client.async_client: Timed out, sleeping for 0s
2025-01-05 03:57:18,306 [WARNING] nio.client.async_client: Timed out, sleeping for 1s
2025-01-05 03:57:19,909 [WARNING] nio.client.async_client: Timed out, sleeping for 3s
2025-01-05 03:57:23,112 [WARNING] nio.client.async_client: Timed out, sleeping for 6s
2025-01-05 03:57:29,516 [WARNING] nio.client.async_client: Timed out, sleeping for 12s
2025-01-05 03:57:42,321 [WARNING] nio.client.async_client: Timed out, sleeping for 25s
2025-01-05 03:58:07,927 [WARNING] nio.client.async_client: Timed out, sleeping for 51s
2025-01-05 03:58:59,134 [WARNING] nio.client.async_client: Timed out, sleeping for 60s
2025-01-05 04:15:50,351 [WARNING] nio.client.async_client: Timed out, sleeping for 60s
2025-01-05 04:33:14,964 [WARNING] nio.client.async_client: Timed out, sleeping for 60s
2025-01-05 04:51:21,819 [WARNING] nio.client.async_client: Timed out, sleeping for 60s
2025-01-05 05:47:49,453 [WARNING] nio.client.async_client: Timed out, sleeping for 60s
2025-01-05 06:01:00,273 [WARNING] nio.client.async_client: Timed out, sleeping for 60s
2025-01-05 06:46:29,345 [WARNING] nio.client.async_client: Timed out, sleeping for 60s
2025-01-05 06:49:07,741 [WARNING] nio.client.async_client: Timed out, sleeping for 60s
2025-01-05 07:24:21,852 [WARNING] nio.client.async_client: Timed out, sleeping for 60s
2025-01-05 07:55:21,896 [WARNING] nio.client.async_client: Timed out, sleeping for 60s
2025-01-05 08:02:53,162 [WARNING] nio.client.async_client: Timed out, sleeping for 60s
2025-01-05 08:49:32,960 [WARNING] nio.client.async_client: Timed out, sleeping for 60s
2025-01-05 09:03:33,661 [WARNING] nio.client.async_client: Timed out, sleeping for 60s
2025-01-05 09:18:35,328 [WARNING] nio.client.async_client: Timed out, sleeping for 60s
2025-01-05 09:19:58,546 [WARNING] nio.client.async_client: Timed out, sleeping for 60s
2025-01-05 09:20:46,479 [WARNING] __main__: KeyboardInterrupt received. Shutting down Director.
2025-01-05 09:20:46,480 [DEBUG] __main__: Preparing to close the event loop.
2025-01-05 09:20:46,480 [INFO] __main__: Event loop closed. Exiting main function.
2025-01-05 09:20:46,513 [ERROR] asyncio: Unclosed client session
client_session: <aiohttp.client.ClientSession object at 0x120999160>
2025-01-05 09:21:12,487 [DEBUG] __main__: Added file handler to root logger. Logging to 'server.log' at DEBUG level.
2025-01-05 09:21:12,487 [DEBUG] __main__: Exiting configure_logging function.
2025-01-05 09:21:12,487 [DEBUG] __main__: Logging configuration complete.
2025-01-05 09:21:12,487 [DEBUG] __main__: Creating a new asyncio event loop.
2025-01-05 09:21:12,487 [DEBUG] asyncio: Using selector: KqueueSelector
2025-01-05 09:21:12,487 [DEBUG] __main__: Set this new loop as the default event loop for the current thread.
2025-01-05 09:21:12,487 [DEBUG] __main__: Stored reference to the new loop in MAIN_LOOP.
2025-01-05 09:21:12,487 [DEBUG] __main__: Entering start_console_thread function.
2025-01-05 09:21:12,488 [INFO] __main__: Console thread started successfully.
2025-01-05 09:21:12,488 [DEBUG] __main__: Exiting start_console_thread function.
2025-01-05 09:21:12,488 [DEBUG] __main__: Console thread has been initiated. Returning to main thread.
2025-01-05 09:21:12,488 [INFO] __main__: Starting main_logic coroutine.
2025-01-05 09:21:12,488 [DEBUG] __main__: Entering main_logic function...
2025-01-05 09:21:12,488 [DEBUG] __main__: Attempting to load or log in the client.
2025-01-05 09:21:12,589 [DEBUG] src.luna_functions: No valid token found, attempting normal password login.
2025-01-05 09:21:12,873 [INFO] src.luna_functions: Password login succeeded, storing token.
2025-01-05 09:21:12,873 [DEBUG] src.luna_functions: Token info for @luna:localhost saved to director_token.json.
2025-01-05 09:21:12,873 [DEBUG] __main__: Client obtained. Storing reference to DIRECTOR_CLIENT in src.luna_functions.
2025-01-05 09:21:12,873 [DEBUG] __main__: Callbacks registered successfully.
2025-01-05 09:21:12,873 [DEBUG] __main__: Starting sync_forever loop. Awaiting new events with timeout=30000.
2025-01-05 09:21:12,886 [INFO] nio.client.base_client: New invited room !PmOiRDooqweqMsXyTN:localhost
2025-01-05 09:21:12,886 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type InviteMemberEvent
2025-01-05 09:21:12,886 [INFO] src.luna_functions: Received invite to !PmOiRDooqweqMsXyTN:localhost, joining now.
2025-01-05 09:21:12,907 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type InviteMemberEvent
2025-01-05 09:21:12,907 [INFO] src.luna_functions: Received invite to !PmOiRDooqweqMsXyTN:localhost, joining now.
2025-01-05 09:21:12,918 [INFO] nio.client.base_client: New invited room !byRaIjLPSRhKcNeUTu:localhost
2025-01-05 09:21:12,918 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type InviteAliasEvent
2025-01-05 09:21:12,918 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type InviteNameEvent
2025-01-05 09:21:12,918 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type InviteMemberEvent
2025-01-05 09:21:12,918 [INFO] src.luna_functions: Received invite to !byRaIjLPSRhKcNeUTu:localhost, joining now.
2025-01-05 09:21:12,940 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type InviteMemberEvent
2025-01-05 09:21:12,940 [INFO] src.luna_functions: Received invite to !byRaIjLPSRhKcNeUTu:localhost, joining now.
2025-01-05 09:21:12,969 [INFO] nio.client.base_client: New joined room !byRaIjLPSRhKcNeUTu:localhost
2025-01-05 09:21:12,969 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomCreateEvent
2025-01-05 09:21:12,969 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type PowerLevelsEvent
2025-01-05 09:21:12,969 [INFO] nio.rooms: Changing power level for user @evan:localhost from 0 to 100
2025-01-05 09:21:12,969 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomAliasEvent
2025-01-05 09:21:12,969 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomJoinRulesEvent
2025-01-05 09:21:12,969 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomHistoryVisibilityEvent
2025-01-05 09:21:12,969 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomNameEvent
2025-01-05 09:21:12,970 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomTopicEvent
2025-01-05 09:21:12,970 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 09:21:12,970 [INFO] src.luna_functions: Fetching last 100 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 09:21:12,975 [INFO] src.luna_functions: Fetched 2 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 09:21:12,975 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'test private channel'}]
2025-01-05 09:21:12,975 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'test private channel'}]
2025-01-05 09:21:13,010 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'test private channel'}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 09:21:13,014 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-01-05 09:21:13,070 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105d0c2f0>
2025-01-05 09:21:13,070 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x105c21520> server_hostname='api.openai.com' timeout=5.0
2025-01-05 09:21:13,096 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105c80690>
2025-01-05 09:21:13,096 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 09:21:13,096 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 09:21:13,097 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 09:21:13,097 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 09:21:13,097 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 09:21:13,628 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 14:21:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'455'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79623'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'282ms'), (b'x-request-id', b'req_9dc8a9cf172b61125b8294d9f0953ff7'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=JWg0ossQPPv8OsHGHUL2VbAV9_vNACHgcTgkrWIku24-1736086873-1.0.1.1-p.8xPA8Ed7ngP8WPURXpYMWrud3oBUMcaE.0L7eYiVtUh9jPC2C.lhPYnThf10MxClwSUNZMfGq28_z5qwCQGg; path=/; expires=Sun, 05-Jan-25 14:51:13 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=f8Sv5F12DnoTa0HscvOLaDjMHO0oua00HPbM.4o60EY-1736086873652-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd41d0d1b24199d-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 09:21:13,629 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 09:21:13,629 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 09:21:13,629 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 09:21:13,629 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 09:21:13,629 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 09:21:13,630 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 09:21:13,634 [INFO] src.luna_functions: GPT response: Hello! How can I assist you with the private channel?
2025-01-05 09:21:13,663 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 09:21:13,663 [INFO] src.luna_functions: Fetching last 100 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 09:21:13,669 [INFO] src.luna_functions: Fetched 3 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 09:21:13,669 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'test'}]
2025-01-05 09:21:13,669 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'test'}]
2025-01-05 09:21:13,672 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'test'}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 09:21:13,673 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 09:21:13,673 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 09:21:13,673 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 09:21:13,674 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 09:21:13,674 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 09:21:15,337 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 14:21:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'1517'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79613'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'290ms'), (b'x-request-id', b'req_03f91ac52a7534254ac9dd2a35651c4d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd41d10bec1199d-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 09:21:15,337 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 09:21:15,337 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 09:21:15,337 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 09:21:15,338 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 09:21:15,338 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 09:21:15,338 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 09:21:15,338 [INFO] src.luna_functions: GPT response: I'm here and ready to assist. How can we test the private channel according to your needs?
2025-01-05 09:21:15,354 [INFO] nio.client.base_client: New joined room !PmOiRDooqweqMsXyTN:localhost
2025-01-05 09:21:15,355 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomCreateEvent
2025-01-05 09:21:15,355 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type PowerLevelsEvent
2025-01-05 09:21:15,355 [INFO] nio.rooms: Changing power level for user @evan:localhost from 0 to 100
2025-01-05 09:21:15,355 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomJoinRulesEvent
2025-01-05 09:21:15,355 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomHistoryVisibilityEvent
2025-01-05 09:21:15,355 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomGuestAccessEvent
2025-01-05 09:21:15,355 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 09:21:15,355 [INFO] src.luna_functions: Fetching last 100 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 09:21:15,362 [INFO] src.luna_functions: Fetched 4 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 09:21:15,362 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'hi'}]
2025-01-05 09:21:15,362 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'hi'}]
2025-01-05 09:21:15,366 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'hi'}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 09:21:15,367 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 09:21:15,367 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 09:21:15,367 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 09:21:15,367 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 09:21:15,367 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 09:21:16,465 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 14:21:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'953'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79626'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'280ms'), (b'x-request-id', b'req_828ee01dc43844a95ae3f6172b275cc8'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd41d1b4efc199d-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 09:21:16,466 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 09:21:16,466 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 09:21:16,467 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 09:21:16,468 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 09:21:16,468 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 09:21:16,468 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 09:21:16,469 [INFO] src.luna_functions: GPT response: Hello! How can I assist you today?
2025-01-05 09:21:16,499 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 09:21:16,499 [INFO] src.luna_functions: Fetching last 100 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 09:21:16,509 [INFO] src.luna_functions: Fetched 5 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 09:21:16,509 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'Pi is 5.14159'}]
2025-01-05 09:21:16,509 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'Pi is 5.14159'}]
2025-01-05 09:21:16,513 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'Pi is 5.14159'}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 09:21:16,514 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 09:21:16,515 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 09:21:16,515 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 09:21:16,515 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 09:21:16,515 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 09:21:17,488 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 14:21:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'896'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79614'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'289ms'), (b'x-request-id', b'req_48885374da25c54549cec3d581493dbe'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd41d227cb6199d-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 09:21:17,490 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 09:21:17,490 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 09:21:17,490 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 09:21:17,491 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 09:21:17,491 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 09:21:17,491 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 09:21:17,492 [INFO] src.luna_functions: GPT response: I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159.
2025-01-05 09:21:17,523 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 09:21:17,523 [INFO] src.luna_functions: Fetching last 100 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 09:21:17,534 [INFO] src.luna_functions: Fetched 6 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 09:21:17,535 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'test'}]
2025-01-05 09:21:17,535 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'test'}]
2025-01-05 09:21:17,542 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'test'}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 09:21:17,543 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 09:21:17,543 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 09:21:17,543 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 09:21:17,543 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 09:21:17,543 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 09:21:18,409 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 14:21:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'727'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79595'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'303ms'), (b'x-request-id', b'req_9b1968ef9f52fddf6c9085ad7fdccfe0'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd41d28ea25199d-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 09:21:18,411 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 09:21:18,411 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 09:21:18,413 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 09:21:18,413 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 09:21:18,413 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 09:21:18,414 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 09:21:18,414 [INFO] src.luna_functions: GPT response: Hello! How can I help you today?
2025-01-05 09:21:18,444 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 09:21:18,444 [INFO] src.luna_functions: Fetching last 100 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 09:21:18,457 [INFO] src.luna_functions: Fetched 7 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 09:21:18,457 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'test'}]
2025-01-05 09:21:18,457 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'test'}]
2025-01-05 09:21:18,466 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'test'}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 09:21:18,468 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 09:21:18,468 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 09:21:18,469 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 09:21:18,469 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 09:21:18,469 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 09:21:19,127 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 14:21:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'485'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79586'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'310ms'), (b'x-request-id', b'req_c302518a68ad4c511fc7d9e4591d4552'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd41d2ea87e199d-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 09:21:19,129 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 09:21:19,129 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 09:21:19,129 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 09:21:19,130 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 09:21:19,130 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 09:21:19,130 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 09:21:19,131 [INFO] src.luna_functions: GPT response: Hello! How can I assist you further?
2025-01-05 09:21:19,183 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 09:21:19,184 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 09:21:19,184 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 09:21:19,184 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 09:21:19,184 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 09:21:19,184 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 09:21:19,184 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 09:21:19,184 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 09:21:19,184 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 09:21:19,184 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 09:21:19,184 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 09:21:19,184 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 09:32:28,196 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 09:32:28,204 [INFO] src.luna_functions: Fetching last 100 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 09:32:28,214 [INFO] src.luna_functions: Fetched 9 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 09:32:28,214 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'WHAT '}]
2025-01-05 09:32:28,214 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'WHAT '}]
2025-01-05 09:32:28,220 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'WHAT '}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 09:32:28,221 [DEBUG] httpcore.connection: close.started
2025-01-05 09:32:28,222 [DEBUG] httpcore.connection: close.complete
2025-01-05 09:32:28,222 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-01-05 09:32:28,274 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105c825d0>
2025-01-05 09:32:28,274 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x105c21520> server_hostname='api.openai.com' timeout=5.0
2025-01-05 09:32:28,299 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105c9f230>
2025-01-05 09:32:28,300 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 09:32:28,300 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 09:32:28,300 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 09:32:28,301 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 09:32:28,301 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 09:32:29,038 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 14:32:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'568'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79573'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'320ms'), (b'x-request-id', b'req_94f945a942ad3502d3c118ff38e21041'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd42d892b39c45c-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 09:32:29,042 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 09:32:29,042 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 09:32:29,043 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 09:32:29,043 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 09:32:29,044 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 09:32:29,044 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 09:32:29,045 [INFO] src.luna_functions: GPT response: I'm here to help! Could you please provide more details or clarify your request?
2025-01-05 09:32:29,090 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 09:32:29,091 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 09:32:33,722 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 09:32:33,723 [INFO] src.luna_functions: Fetching last 100 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 09:32:33,735 [INFO] src.luna_functions: Fetched 5 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 09:32:33,735 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'test'}]
2025-01-05 09:32:33,735 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'test'}]
2025-01-05 09:32:33,739 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'test'}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 09:32:33,740 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 09:32:33,740 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 09:32:33,740 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 09:32:33,740 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 09:32:33,740 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 09:32:35,142 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 14:32:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'1333'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79588'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'309ms'), (b'x-request-id', b'req_bac753be8b29df0644671bc1933626b7'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd42dab2b12c45c-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 09:32:35,147 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 09:32:35,148 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 09:32:35,149 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 09:32:35,149 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 09:32:35,150 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 09:32:35,150 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 09:32:35,151 [INFO] src.luna_functions: GPT response: I'm here and ready to assist. How may I help you with the test?
2025-01-05 09:32:35,201 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 09:32:35,202 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 09:33:29,517 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 09:33:29,518 [INFO] src.luna_functions: Fetching last 100 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 09:33:29,530 [INFO] src.luna_functions: Fetched 7 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 09:33:29,530 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'great'}]
2025-01-05 09:33:29,531 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'great'}]
2025-01-05 09:33:29,536 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'great'}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 09:33:29,536 [DEBUG] httpcore.connection: close.started
2025-01-05 09:33:29,537 [DEBUG] httpcore.connection: close.complete
2025-01-05 09:33:29,537 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-01-05 09:33:29,585 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105c9c3e0>
2025-01-05 09:33:29,586 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x105c21520> server_hostname='api.openai.com' timeout=5.0
2025-01-05 09:33:29,611 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105c89910>
2025-01-05 09:33:29,611 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 09:33:29,611 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 09:33:29,612 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 09:33:29,612 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 09:33:29,612 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 09:33:30,581 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 14:33:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'834'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79568'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'324ms'), (b'x-request-id', b'req_ea73974fbc5364b6407f8c60d35104e3'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd42f086eb71875-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 09:33:30,583 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 09:33:30,583 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 09:33:30,584 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 09:33:30,584 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 09:33:30,584 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 09:33:30,585 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 09:33:30,585 [INFO] src.luna_functions: GPT response: I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask.
2025-01-05 09:33:30,633 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 09:33:30,634 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 09:33:33,401 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 09:33:33,402 [INFO] src.luna_functions: Fetching last 100 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 09:33:33,413 [INFO] src.luna_functions: Fetched 9 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 09:33:33,413 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': "what's your ae"}]
2025-01-05 09:33:33,414 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': "what's your ae"}]
2025-01-05 09:33:33,427 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': "what's your ae"}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 09:33:33,428 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 09:33:33,429 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 09:33:33,429 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 09:33:33,429 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 09:33:33,429 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 09:33:35,404 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 14:33:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'1909'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79529'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'353ms'), (b'x-request-id', b'req_0bab404a58d9325c051bc864ddf846e3'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd42f203c551875-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 09:33:35,405 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 09:33:35,405 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 09:33:35,406 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 09:33:35,406 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 09:33:35,406 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 09:33:35,407 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 09:33:35,408 [INFO] src.luna_functions: GPT response: I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?
2025-01-05 09:33:35,475 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 09:33:35,475 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 09:33:39,378 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 09:33:39,378 [INFO] src.luna_functions: Fetching last 100 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 09:33:39,390 [INFO] src.luna_functions: Fetched 11 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 09:33:39,390 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': "I'm steve"}]
2025-01-05 09:33:39,391 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': "I'm steve"}]
2025-01-05 09:33:39,397 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': "I'm steve"}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 09:33:39,398 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 09:33:39,398 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 09:33:39,398 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 09:33:39,398 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 09:33:39,398 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 09:33:40,821 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 14:33:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'1242'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79494'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'379ms'), (b'x-request-id', b'req_d3c7dc3fa7f8c8a41378908813eaab4d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd42f458ad81875-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 09:33:40,823 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 09:33:40,823 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 09:33:40,824 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 09:33:40,824 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 09:33:40,824 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 09:33:40,825 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 09:33:40,825 [INFO] src.luna_functions: GPT response: Nice to meet you, Steve. How can I assist you today?
2025-01-05 09:33:40,869 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 09:33:40,870 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 09:33:47,363 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 09:33:47,364 [INFO] src.luna_functions: Fetching last 100 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 09:33:47,376 [INFO] src.luna_functions: Fetched 13 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 09:33:47,376 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'I need help figuring out a math problem'}]
2025-01-05 09:33:47,376 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'I need help figuring out a math problem'}]
2025-01-05 09:33:47,384 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'I need help figuring out a math problem'}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 09:33:47,384 [DEBUG] httpcore.connection: close.started
2025-01-05 09:33:47,385 [DEBUG] httpcore.connection: close.complete
2025-01-05 09:33:47,385 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-01-05 09:33:47,410 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105cc2690>
2025-01-05 09:33:47,411 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x105c21520> server_hostname='api.openai.com' timeout=5.0
2025-01-05 09:33:47,437 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105cc1d00>
2025-01-05 09:33:47,437 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 09:33:47,438 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 09:33:47,438 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 09:33:47,438 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 09:33:47,438 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 09:33:48,602 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 14:33:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'979'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79462'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'403ms'), (b'x-request-id', b'req_0553f500f132687301e31772504f31b7'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd42f77ce4c0fa1-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 09:33:48,610 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 09:33:48,610 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 09:33:48,611 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 09:33:48,611 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 09:33:48,611 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 09:33:48,612 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 09:33:48,612 [INFO] src.luna_functions: GPT response: Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?
2025-01-05 09:33:48,663 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 09:33:48,664 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 09:33:51,779 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 09:33:51,779 [INFO] src.luna_functions: Fetching last 100 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 09:33:51,790 [INFO] src.luna_functions: Fetched 15 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 09:33:51,790 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': "It's about pi"}]
2025-01-05 09:33:51,790 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': "It's about pi"}]
2025-01-05 09:33:51,797 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': "It's about pi"}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 09:33:51,798 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 09:33:51,798 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 09:33:51,798 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 09:33:51,798 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 09:33:51,798 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 09:33:53,109 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 14:33:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'1192'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79438'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'421ms'), (b'x-request-id', b'req_4c10837de8e712e90218f56d4c8fbb9c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd42f930d0c0fa1-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 09:33:53,110 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 09:33:53,110 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 09:33:53,111 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 09:33:53,111 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 09:33:53,111 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 09:33:53,111 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 09:33:53,112 [INFO] src.luna_functions: GPT response: Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?
2025-01-05 09:33:53,160 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 09:33:53,161 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 09:34:03,664 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 09:34:03,665 [INFO] src.luna_functions: Fetching last 100 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 09:34:03,682 [INFO] src.luna_functions: Fetched 17 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 09:34:03,682 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}]
2025-01-05 09:34:03,682 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}]
2025-01-05 09:34:03,693 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 09:34:03,693 [DEBUG] httpcore.connection: close.started
2025-01-05 09:34:03,694 [DEBUG] httpcore.connection: close.complete
2025-01-05 09:34:03,694 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-01-05 09:34:03,745 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105d7c450>
2025-01-05 09:34:03,745 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x105c21520> server_hostname='api.openai.com' timeout=5.0
2025-01-05 09:34:03,766 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105d7c650>
2025-01-05 09:34:03,767 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 09:34:03,767 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 09:34:03,767 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 09:34:03,768 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 09:34:03,768 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 09:34:07,060 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 14:34:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'3212'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79351'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'486ms'), (b'x-request-id', b'req_e46f00a2f03ab938782754f7fe79dc5e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd42fdddf71236b-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 09:34:07,062 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 09:34:07,062 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 09:34:07,063 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 09:34:07,063 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 09:34:07,064 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 09:34:07,064 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 09:34:07,065 [INFO] src.luna_functions: GPT response: As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!
2025-01-05 09:34:07,117 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 09:34:07,117 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 09:34:12,841 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 09:34:12,841 [INFO] src.luna_functions: Fetching last 100 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 09:34:12,855 [INFO] src.luna_functions: Fetched 19 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 09:34:12,856 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'what do I need help with again'}]
2025-01-05 09:34:12,856 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'what do I need help with again'}]
2025-01-05 09:34:12,866 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'what do I need help with again'}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 09:34:12,867 [DEBUG] httpcore.connection: close.started
2025-01-05 09:34:12,867 [DEBUG] httpcore.connection: close.complete
2025-01-05 09:34:12,867 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-01-05 09:34:12,894 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105c0b020>
2025-01-05 09:34:12,894 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x105c21520> server_hostname='api.openai.com' timeout=5.0
2025-01-05 09:34:12,921 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105da05f0>
2025-01-05 09:34:12,922 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 09:34:12,922 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 09:34:12,922 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 09:34:12,923 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 09:34:12,923 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 09:34:14,816 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 14:34:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'1758'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79315'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'513ms'), (b'x-request-id', b'req_1617d4b4b0a0e1b11c0cc1343abb2845'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd43017181a4225-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 09:34:14,818 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 09:34:14,818 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 09:34:14,819 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 09:34:14,819 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 09:34:14,819 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 09:34:14,820 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 09:34:14,820 [INFO] src.luna_functions: GPT response: Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?
2025-01-05 09:34:14,875 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 09:34:14,876 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 09:34:23,404 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 09:34:23,404 [INFO] src.luna_functions: Fetching last 100 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 09:34:23,416 [INFO] src.luna_functions: Fetched 21 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 09:34:23,416 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': "what's my name?"}]
2025-01-05 09:34:23,416 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': "what's my name?"}]
2025-01-05 09:34:23,426 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': "what's my name?"}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 09:34:23,427 [DEBUG] httpcore.connection: close.started
2025-01-05 09:34:23,427 [DEBUG] httpcore.connection: close.complete
2025-01-05 09:34:23,427 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-01-05 09:34:23,454 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105d26890>
2025-01-05 09:34:23,455 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x105c21520> server_hostname='api.openai.com' timeout=5.0
2025-01-05 09:34:23,474 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105d26a50>
2025-01-05 09:34:23,475 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 09:34:23,475 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 09:34:23,475 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 09:34:23,476 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 09:34:23,476 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 09:34:26,900 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 14:34:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'3261'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79273'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'545ms'), (b'x-request-id', b'req_f062d2ed98845ab7b1cc45bfc32d7f18'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd430590a110f37-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 09:34:26,905 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 09:34:26,905 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 09:34:26,905 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 09:34:26,905 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 09:34:26,906 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 09:34:26,906 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 09:34:26,906 [INFO] src.luna_functions: GPT response: I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality.
2025-01-05 09:34:26,959 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 09:34:26,959 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 09:34:39,229 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 09:34:39,229 [INFO] src.luna_functions: Fetching last 100 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 09:34:39,247 [INFO] src.luna_functions: Fetched 11 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 09:34:39,247 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'what did I want help with'}]
2025-01-05 09:34:39,247 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'what did I want help with'}]
2025-01-05 09:34:39,253 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'what did I want help with'}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 09:34:39,254 [DEBUG] httpcore.connection: close.started
2025-01-05 09:34:39,254 [DEBUG] httpcore.connection: close.complete
2025-01-05 09:34:39,254 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-01-05 09:34:39,287 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105cd97e0>
2025-01-05 09:34:39,287 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x105c21520> server_hostname='api.openai.com' timeout=5.0
2025-01-05 09:34:39,311 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105dad250>
2025-01-05 09:34:39,312 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 09:34:39,313 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 09:34:39,313 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 09:34:39,313 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 09:34:39,313 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 09:34:40,833 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 14:34:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'1402'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79540'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'345ms'), (b'x-request-id', b'req_6e6f209856dd47c163b9b652ebe4ed28'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd430bc0d00de9b-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 09:34:40,834 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 09:34:40,835 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 09:34:40,835 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 09:34:40,835 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 09:34:40,836 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 09:34:40,836 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 09:34:40,836 [INFO] src.luna_functions: GPT response: I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?
2025-01-05 09:34:40,873 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 09:34:40,873 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:41:27,175 [INFO] src.console_functions: Console received 'restart' command; restarting now.
2025-01-05 12:41:27,918 [DEBUG] __main__: Added file handler to root logger. Logging to 'server.log' at DEBUG level.
2025-01-05 12:41:27,918 [DEBUG] __main__: Exiting configure_logging function.
2025-01-05 12:41:27,918 [DEBUG] __main__: Logging configuration complete.
2025-01-05 12:41:27,918 [DEBUG] __main__: Creating a new asyncio event loop.
2025-01-05 12:41:27,918 [DEBUG] asyncio: Using selector: KqueueSelector
2025-01-05 12:41:27,918 [DEBUG] __main__: Set this new loop as the default event loop for the current thread.
2025-01-05 12:41:27,918 [DEBUG] __main__: Stored reference to the new loop in MAIN_LOOP.
2025-01-05 12:41:27,918 [DEBUG] __main__: Entering start_console_thread function.
2025-01-05 12:41:27,918 [INFO] __main__: Console thread started successfully.
2025-01-05 12:41:27,918 [DEBUG] __main__: Exiting start_console_thread function.
2025-01-05 12:41:27,918 [DEBUG] __main__: Console thread has been initiated. Returning to main thread.
2025-01-05 12:41:27,918 [INFO] __main__: Starting main_logic coroutine.
2025-01-05 12:41:27,918 [DEBUG] __main__: Entering main_logic function...
2025-01-05 12:41:27,918 [DEBUG] __main__: Attempting to load or log in the client.
2025-01-05 12:41:28,020 [DEBUG] src.luna_functions: Found director_token.json, attempting token-based login.
2025-01-05 12:41:28,020 [DEBUG] src.luna_functions: Loading client with saved token credentials.
2025-01-05 12:41:28,020 [INFO] src.luna_functions: Using saved token for user @luna:localhost.
2025-01-05 12:41:28,020 [DEBUG] __main__: Client obtained. Storing reference to DIRECTOR_CLIENT in src.luna_functions.
2025-01-05 12:41:28,020 [DEBUG] __main__: Callbacks registered successfully.
2025-01-05 12:41:28,020 [DEBUG] __main__: Starting sync_forever loop. Awaiting new events with timeout=30000.
2025-01-05 12:41:28,066 [INFO] nio.client.base_client: New joined room !byRaIjLPSRhKcNeUTu:localhost
2025-01-05 12:41:28,066 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomTopicEvent
2025-01-05 12:41:28,066 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomNameEvent
2025-01-05 12:41:28,066 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomAliasEvent
2025-01-05 12:41:28,066 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomJoinRulesEvent
2025-01-05 12:41:28,066 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type PowerLevelsEvent
2025-01-05 12:41:28,066 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomCreateEvent
2025-01-05 12:41:28,066 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomHistoryVisibilityEvent
2025-01-05 12:41:28,066 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:41:28,066 [INFO] src.luna_functions: Fetching last 100 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 12:41:28,075 [INFO] src.luna_functions: Fetched 22 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 12:41:28,075 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'I need help figuring out a math problem'}]
2025-01-05 12:41:28,075 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'I need help figuring out a math problem'}]
2025-01-05 12:41:28,111 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'I need help figuring out a math problem'}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 12:41:28,115 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-01-05 12:41:28,261 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11616c2f0>
2025-01-05 12:41:28,261 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x110f69520> server_hostname='api.openai.com' timeout=5.0
2025-01-05 12:41:28,338 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x110fda350>
2025-01-05 12:41:28,338 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 12:41:28,339 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 12:41:28,339 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 12:41:28,339 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 12:41:28,339 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 12:41:29,559 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 17:41:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'1098'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79211'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'591ms'), (b'x-request-id', b'req_41e118214c5e1efeaa820f161063cc5d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=_Xmts2.yJeB3Isu2cv01QDxrhBfoa.ABjN1hlqu60j0-1736098889-1.0.1.1-wLzIWAduRZvTeo2o0v9z8RMmT8PZLvbeUlP0Jg1aDgR.naLybwLatbzpNj5Q8b0iDoPQEStDEzjPIHxUjwlTGA; path=/; expires=Sun, 05-Jan-25 18:11:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=1YKN8FTUpYRO3fMy3iGUSOPYETBnqya_bsBpG1h9eJU-1736098889559-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd54264894441a3-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 12:41:29,562 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 12:41:29,563 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 12:41:29,567 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 12:41:29,567 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 12:41:29,567 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 12:41:29,567 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 12:41:29,573 [INFO] src.luna_functions: GPT response: Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?
2025-01-05 12:41:29,632 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:41:29,633 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:41:29,633 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:41:29,633 [INFO] src.luna_functions: Fetching last 100 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 12:41:29,655 [INFO] src.luna_functions: Fetched 23 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 12:41:29,655 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': "It's about pi"}]
2025-01-05 12:41:29,655 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': "It's about pi"}]
2025-01-05 12:41:29,668 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': "It's about pi"}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 12:41:29,669 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 12:41:29,669 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 12:41:29,669 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 12:41:29,670 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 12:41:29,670 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 12:41:30,585 [DEBUG] src.console_functions: Showing help to user.
2025-01-05 12:41:30,963 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 17:41:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'1142'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79182'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'613ms'), (b'x-request-id', b'req_cf30d02193e89aca64f48615266141aa'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd5426d0c4141a3-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 12:41:30,965 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 12:41:30,965 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 12:41:30,966 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 12:41:30,966 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 12:41:30,966 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 12:41:30,967 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 12:41:30,968 [INFO] src.luna_functions: GPT response: Sure, I'd be happy to help you with your question about Pi. Could you please provide me with the details of the problem you're trying to solve?
2025-01-05 12:41:31,002 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:41:31,002 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:41:31,003 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:41:31,003 [INFO] src.luna_functions: Fetching last 100 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 12:41:31,036 [INFO] src.luna_functions: Fetched 24 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 12:41:31,036 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your question about Pi. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}]
2025-01-05 12:41:31,036 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your question about Pi. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}]
2025-01-05 12:41:31,049 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your question about Pi. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 12:41:31,050 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 12:41:31,050 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 12:41:31,050 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 12:41:31,050 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 12:41:31,050 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 12:41:34,138 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 17:41:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'2569'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79135'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'648ms'), (b'x-request-id', b'req_2e9a5045c0d7b3fd753fd58b9fb1104a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd54275882d41a3-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 12:41:34,139 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 12:41:34,140 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 12:41:34,140 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 12:41:34,140 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 12:41:34,141 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 12:41:34,141 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 12:41:34,142 [INFO] src.luna_functions: GPT response: As an AI, I don't have personal experiences or preferences, but I can provide information about apple pie or Pi (the mathematical constant). How can I assist you further?
2025-01-05 12:41:34,171 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:41:34,171 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:41:34,171 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:41:34,172 [INFO] src.luna_functions: Fetching last 100 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 12:41:34,190 [INFO] src.luna_functions: Fetched 25 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 12:41:34,191 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "As an AI, I don't have personal experiences or preferences, but I can provide information about apple pie or Pi (the mathematical constant). How can I assist you further?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your question about Pi. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'what do I need help with again'}]
2025-01-05 12:41:34,191 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "As an AI, I don't have personal experiences or preferences, but I can provide information about apple pie or Pi (the mathematical constant). How can I assist you further?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your question about Pi. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'what do I need help with again'}]
2025-01-05 12:41:34,209 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "As an AI, I don't have personal experiences or preferences, but I can provide information about apple pie or Pi (the mathematical constant). How can I assist you further?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your question about Pi. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'what do I need help with again'}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 12:41:34,210 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 12:41:34,210 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 12:41:34,210 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 12:41:34,210 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 12:41:34,210 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 12:41:36,906 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 17:41:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'2303'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79097'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'677ms'), (b'x-request-id', b'req_794da44d4d8df37d68e973da3aeb8dd9'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd54289597b41a3-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 12:41:36,907 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 12:41:36,907 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 12:41:36,907 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 12:41:36,908 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 12:41:36,908 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 12:41:36,908 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 12:41:36,908 [INFO] src.luna_functions: GPT response: From our previous conversations, it appears you were looking for assistance with a math problem related to Pi, the mathematical constant. Can you provide more specific details about this problem so I can assist you better?
2025-01-05 12:41:36,945 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:41:36,945 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:41:36,945 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:41:36,945 [INFO] src.luna_functions: Fetching last 100 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 12:41:36,958 [INFO] src.luna_functions: Fetched 26 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 12:41:36,958 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'From our previous conversations, it appears you were looking for assistance with a math problem related to Pi, the mathematical constant. Can you provide more specific details about this problem so I can assist you better?'}, {'role': 'user', 'content': "As an AI, I don't have personal experiences or preferences, but I can provide information about apple pie or Pi (the mathematical constant). How can I assist you further?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your question about Pi. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': "what's my name?"}]
2025-01-05 12:41:36,958 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'From our previous conversations, it appears you were looking for assistance with a math problem related to Pi, the mathematical constant. Can you provide more specific details about this problem so I can assist you better?'}, {'role': 'user', 'content': "As an AI, I don't have personal experiences or preferences, but I can provide information about apple pie or Pi (the mathematical constant). How can I assist you further?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your question about Pi. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': "what's my name?"}]
2025-01-05 12:41:36,977 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'From our previous conversations, it appears you were looking for assistance with a math problem related to Pi, the mathematical constant. Can you provide more specific details about this problem so I can assist you better?'}, {'role': 'user', 'content': "As an AI, I don't have personal experiences or preferences, but I can provide information about apple pie or Pi (the mathematical constant). How can I assist you further?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your question about Pi. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': "what's my name?"}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 12:41:36,978 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 12:41:36,978 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 12:41:36,978 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 12:41:36,978 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 12:41:36,978 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 12:41:39,255 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 17:41:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'1976'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79045'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'716ms'), (b'x-request-id', b'req_cf1681519808271f718836d018ee9e2e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd5429a8a7041a3-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 12:41:39,256 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 12:41:39,256 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 12:41:39,256 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 12:41:39,256 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 12:41:39,256 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 12:41:39,256 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 12:41:39,257 [INFO] src.luna_functions: GPT response: I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality.
2025-01-05 12:41:39,287 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:41:39,287 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:41:39,287 [INFO] nio.client.base_client: New joined room !PmOiRDooqweqMsXyTN:localhost
2025-01-05 12:41:39,287 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type PowerLevelsEvent
2025-01-05 12:41:39,287 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomGuestAccessEvent
2025-01-05 12:41:39,287 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomHistoryVisibilityEvent
2025-01-05 12:41:39,287 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomJoinRulesEvent
2025-01-05 12:41:39,287 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomCreateEvent
2025-01-05 12:41:39,287 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:41:39,287 [INFO] src.luna_functions: Fetching last 100 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 12:41:39,298 [INFO] src.luna_functions: Fetched 12 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 12:41:39,298 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'test'}]
2025-01-05 12:41:39,298 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'test'}]
2025-01-05 12:41:39,306 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'test'}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 12:41:39,307 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 12:41:39,308 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 12:41:39,308 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 12:41:39,308 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 12:41:39,308 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 12:41:41,818 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 17:41:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'1933'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79505'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'371ms'), (b'x-request-id', b'req_77beda2ffc2f38bfc936ac4dfb660d1b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd542a91cd041a3-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 12:41:41,819 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 12:41:41,819 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 12:41:41,820 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 12:41:41,820 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 12:41:41,820 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 12:41:41,820 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 12:41:41,821 [INFO] src.luna_functions: GPT response: Hello! How can I assist you today?
2025-01-05 12:41:41,851 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:41:41,851 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:41:41,851 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:41:41,851 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:41:41,851 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:41:41,851 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:41:41,851 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:41:41,851 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:41:41,851 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:41:41,851 [INFO] src.luna_functions: Fetching last 100 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 12:41:41,859 [INFO] src.luna_functions: Fetched 13 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 12:41:41,859 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'WHAT '}]
2025-01-05 12:41:41,859 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'WHAT '}]
2025-01-05 12:41:41,868 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'WHAT '}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 12:41:41,868 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 12:41:41,868 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 12:41:41,869 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 12:41:41,869 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 12:41:41,869 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 12:41:43,361 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 17:41:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'950'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79495'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'378ms'), (b'x-request-id', b'req_0b2d494a6bd861c72d675e71731fd065'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd542b919d141a3-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 12:41:43,362 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 12:41:43,362 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 12:41:43,363 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 12:41:43,363 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 12:41:43,363 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 12:41:43,363 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 12:41:43,364 [INFO] src.luna_functions: GPT response: I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?
2025-01-05 12:41:43,394 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:41:43,394 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:41:43,394 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:41:43,394 [INFO] src.luna_functions: Fetching last 100 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 12:41:43,404 [INFO] src.luna_functions: Fetched 14 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 12:41:43,404 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'what did I want help with'}]
2025-01-05 12:41:43,405 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'what did I want help with'}]
2025-01-05 12:41:43,430 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'what did I want help with'}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 12:41:43,431 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 12:41:43,432 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 12:41:43,432 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 12:41:43,432 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 12:41:43,432 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 12:41:44,893 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 17:41:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'1156'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79461'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'404ms'), (b'x-request-id', b'req_cb61240fb8792384f2d94e9f94bb3d00'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd542c2ef5341a3-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 12:41:44,894 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 12:41:44,894 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 12:41:44,895 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 12:41:44,895 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 12:41:44,895 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 12:41:44,896 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 12:41:44,897 [INFO] src.luna_functions: GPT response: I'm sorry, but the previous messages don't provide specific details about what you need help with. Could you please clarify or provide more information so I can assist you better?
2025-01-05 12:41:44,936 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:41:44,937 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:41:44,942 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:41:44,942 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:41:44,951 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:41:44,952 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:41:44,952 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:41:44,952 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:41:44,952 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:41:44,952 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:41:44,952 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:41:44,952 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:41:44,952 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:41:44,952 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:41:44,952 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:41:44,952 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:41:44,952 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:41:44,952 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:41:47,290 [INFO] src.console_functions: Console received 'check-limit' command. Checking for rate-limit...
2025-01-05 12:41:47,291 [ERROR] src.luna_functions: check_rate_limit encountered an error: 'AsyncClient' object has no attribute 'session'
Traceback (most recent call last):
  File "/Users/evanrobinson/Documents/Luna2/luna/src/luna_functions.py", line 253, in check_rate_limit
    async with DIRECTOR_CLIENT.session.get(url, headers=headers) as resp:
               ^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'AsyncClient' object has no attribute 'session'
2025-01-05 12:42:00,983 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:42:00,984 [INFO] src.luna_functions: Fetching last 100 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 12:42:01,001 [INFO] src.luna_functions: Fetched 16 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 12:42:01,001 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'hello'}, {'role': 'user', 'content': "I'm sorry, but the previous messages don't provide specific details about what you need help with. Could you please clarify or provide more information so I can assist you better?"}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'hello'}]
2025-01-05 12:42:01,001 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'hello'}, {'role': 'user', 'content': "I'm sorry, but the previous messages don't provide specific details about what you need help with. Could you please clarify or provide more information so I can assist you better?"}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'hello'}]
2025-01-05 12:42:01,009 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'hello'}, {'role': 'user', 'content': "I'm sorry, but the previous messages don't provide specific details about what you need help with. Could you please clarify or provide more information so I can assist you better?"}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 12:42:01,010 [DEBUG] httpcore.connection: close.started
2025-01-05 12:42:01,010 [DEBUG] httpcore.connection: close.complete
2025-01-05 12:42:01,010 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-01-05 12:42:01,078 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x110fdbed0>
2025-01-05 12:42:01,078 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x110f69520> server_hostname='api.openai.com' timeout=5.0
2025-01-05 12:42:01,153 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x110fe1350>
2025-01-05 12:42:01,153 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 12:42:01,154 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 12:42:01,154 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 12:42:01,154 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 12:42:01,154 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 12:42:01,787 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 17:42:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'493'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79418'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'436ms'), (b'x-request-id', b'req_a0a4e8a518a8a50efbc11c64bc6cdd84'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd54331aaf97d0c-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 12:42:01,788 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 12:42:01,789 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 12:42:01,789 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 12:42:01,790 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 12:42:01,791 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 12:42:01,791 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 12:42:01,792 [INFO] src.luna_functions: GPT response: Hello! How can I assist you today?
2025-01-05 12:42:01,830 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:42:01,830 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:42:07,685 [INFO] src.console_functions: Console screen cleared.
2025-01-05 12:42:36,910 [INFO] src.console_functions: Console received 'restart' command; restarting now.
2025-01-05 12:42:37,516 [DEBUG] __main__: Added file handler to root logger. Logging to 'server.log' at DEBUG level.
2025-01-05 12:42:37,516 [DEBUG] __main__: Exiting configure_logging function.
2025-01-05 12:42:37,516 [DEBUG] __main__: Logging configuration complete.
2025-01-05 12:42:37,516 [DEBUG] __main__: Creating a new asyncio event loop.
2025-01-05 12:42:37,516 [DEBUG] asyncio: Using selector: KqueueSelector
2025-01-05 12:42:37,516 [DEBUG] __main__: Set this new loop as the default event loop for the current thread.
2025-01-05 12:42:37,516 [DEBUG] __main__: Stored reference to the new loop in MAIN_LOOP.
2025-01-05 12:42:37,516 [DEBUG] __main__: Entering start_console_thread function.
2025-01-05 12:42:37,516 [INFO] __main__: Console thread started successfully.
2025-01-05 12:42:37,516 [DEBUG] __main__: Exiting start_console_thread function.
2025-01-05 12:42:37,516 [DEBUG] __main__: Console thread has been initiated. Returning to main thread.
2025-01-05 12:42:37,516 [INFO] __main__: Starting main_logic coroutine.
2025-01-05 12:42:37,516 [DEBUG] __main__: Entering main_logic function...
2025-01-05 12:42:37,516 [DEBUG] __main__: Attempting to load or log in the client.
2025-01-05 12:42:37,548 [DEBUG] src.console_functions: Showing help to user.
2025-01-05 12:42:37,618 [DEBUG] src.luna_functions: Found director_token.json, attempting token-based login.
2025-01-05 12:42:37,618 [DEBUG] src.luna_functions: Loading client with saved token credentials.
2025-01-05 12:42:37,618 [INFO] src.luna_functions: Using saved token for user @luna:localhost.
2025-01-05 12:42:37,618 [DEBUG] __main__: Client obtained. Storing reference to DIRECTOR_CLIENT in src.luna_functions.
2025-01-05 12:42:37,618 [DEBUG] __main__: Callbacks registered successfully.
2025-01-05 12:42:37,618 [DEBUG] __main__: Starting sync_forever loop. Awaiting new events with timeout=30000.
2025-01-05 12:42:37,637 [INFO] nio.client.base_client: New joined room !byRaIjLPSRhKcNeUTu:localhost
2025-01-05 12:42:37,637 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomTopicEvent
2025-01-05 12:42:37,637 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomNameEvent
2025-01-05 12:42:37,637 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomAliasEvent
2025-01-05 12:42:37,637 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomJoinRulesEvent
2025-01-05 12:42:37,637 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type PowerLevelsEvent
2025-01-05 12:42:37,637 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomCreateEvent
2025-01-05 12:42:37,637 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomHistoryVisibilityEvent
2025-01-05 12:42:37,637 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:42:37,637 [INFO] src.luna_functions: Fetching last 100 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 12:42:37,655 [INFO] src.luna_functions: Fetched 27 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 12:42:37,655 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': 'From our previous conversations, it appears you were looking for assistance with a math problem related to Pi, the mathematical constant. Can you provide more specific details about this problem so I can assist you better?'}, {'role': 'user', 'content': "As an AI, I don't have personal experiences or preferences, but I can provide information about apple pie or Pi (the mathematical constant). How can I assist you further?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your question about Pi. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'I need help figuring out a math problem'}]
2025-01-05 12:42:37,655 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': 'From our previous conversations, it appears you were looking for assistance with a math problem related to Pi, the mathematical constant. Can you provide more specific details about this problem so I can assist you better?'}, {'role': 'user', 'content': "As an AI, I don't have personal experiences or preferences, but I can provide information about apple pie or Pi (the mathematical constant). How can I assist you further?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your question about Pi. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'I need help figuring out a math problem'}]
2025-01-05 12:42:37,683 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': 'From our previous conversations, it appears you were looking for assistance with a math problem related to Pi, the mathematical constant. Can you provide more specific details about this problem so I can assist you better?'}, {'role': 'user', 'content': "As an AI, I don't have personal experiences or preferences, but I can provide information about apple pie or Pi (the mathematical constant). How can I assist you further?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your question about Pi. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'I need help figuring out a math problem'}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 12:42:37,687 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-01-05 12:42:37,742 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10c5701a0>
2025-01-05 12:42:37,742 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x10c321520> server_hostname='api.openai.com' timeout=5.0
2025-01-05 12:42:37,818 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10c391950>
2025-01-05 12:42:37,818 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 12:42:37,818 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 12:42:37,818 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 12:42:37,818 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 12:42:37,818 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 12:42:39,297 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 17:42:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'1346'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'78983'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'762ms'), (b'x-request-id', b'req_d689b3d1724bdfaccffa180beb7cc818'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=xHzdHwqAxngGfCPCn1UAm7c3BmRJrHEeKEH16GGRAc4-1736098959-1.0.1.1-3wmz_LvGG.97vhBmt4k3O8xqn0y0OP2T2W_SRbj6qT8UA6ZjmiCzSCsMt67.5FSL3Dg236_B2bwXFasLJ0VsRw; path=/; expires=Sun, 05-Jan-25 18:12:39 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=korICDvDsnG3WQ13my_11YJ8U9bhx5K2RcMQTTpQj8o-1736098959294-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd54416def84408-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 12:42:39,299 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 12:42:39,300 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 12:42:39,301 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 12:42:39,301 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 12:42:39,301 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 12:42:39,301 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 12:42:39,306 [INFO] src.luna_functions: GPT response: Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?
2025-01-05 12:42:39,343 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:42:39,343 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:42:39,343 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:42:39,343 [INFO] src.luna_functions: Fetching last 100 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 12:42:39,368 [INFO] src.luna_functions: Fetched 28 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 12:42:39,368 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': 'From our previous conversations, it appears you were looking for assistance with a math problem related to Pi, the mathematical constant. Can you provide more specific details about this problem so I can assist you better?'}, {'role': 'user', 'content': "As an AI, I don't have personal experiences or preferences, but I can provide information about apple pie or Pi (the mathematical constant). How can I assist you further?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your question about Pi. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': "It's about pi"}]
2025-01-05 12:42:39,368 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': 'From our previous conversations, it appears you were looking for assistance with a math problem related to Pi, the mathematical constant. Can you provide more specific details about this problem so I can assist you better?'}, {'role': 'user', 'content': "As an AI, I don't have personal experiences or preferences, but I can provide information about apple pie or Pi (the mathematical constant). How can I assist you further?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your question about Pi. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': "It's about pi"}]
2025-01-05 12:42:39,386 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': 'From our previous conversations, it appears you were looking for assistance with a math problem related to Pi, the mathematical constant. Can you provide more specific details about this problem so I can assist you better?'}, {'role': 'user', 'content': "As an AI, I don't have personal experiences or preferences, but I can provide information about apple pie or Pi (the mathematical constant). How can I assist you further?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your question about Pi. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': "It's about pi"}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 12:42:39,387 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 12:42:39,387 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 12:42:39,387 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 12:42:39,387 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 12:42:39,387 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 12:42:41,114 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 17:42:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'1276'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'78954'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'784ms'), (b'x-request-id', b'req_983aa8108ed7ac634f7e88c469bad02c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd54421cad94408-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 12:42:41,115 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 12:42:41,115 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 12:42:41,116 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 12:42:41,116 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 12:42:41,116 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 12:42:41,116 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 12:42:41,117 [INFO] src.luna_functions: GPT response: Understood, you need help with a problem related to Pi. Could you please specify the problem so I can assist you more effectively? Are we dealing with geometry, trigonometry, or another area of math?
2025-01-05 12:42:41,147 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:42:41,148 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:42:41,148 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:42:41,148 [INFO] src.luna_functions: Fetching last 100 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 12:42:41,167 [INFO] src.luna_functions: Fetched 29 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 12:42:41,168 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Understood, you need help with a problem related to Pi. Could you please specify the problem so I can assist you more effectively? Are we dealing with geometry, trigonometry, or another area of math?'}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': 'From our previous conversations, it appears you were looking for assistance with a math problem related to Pi, the mathematical constant. Can you provide more specific details about this problem so I can assist you better?'}, {'role': 'user', 'content': "As an AI, I don't have personal experiences or preferences, but I can provide information about apple pie or Pi (the mathematical constant). How can I assist you further?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your question about Pi. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}]
2025-01-05 12:42:41,168 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Understood, you need help with a problem related to Pi. Could you please specify the problem so I can assist you more effectively? Are we dealing with geometry, trigonometry, or another area of math?'}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': 'From our previous conversations, it appears you were looking for assistance with a math problem related to Pi, the mathematical constant. Can you provide more specific details about this problem so I can assist you better?'}, {'role': 'user', 'content': "As an AI, I don't have personal experiences or preferences, but I can provide information about apple pie or Pi (the mathematical constant). How can I assist you further?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your question about Pi. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}]
2025-01-05 12:42:41,190 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Understood, you need help with a problem related to Pi. Could you please specify the problem so I can assist you more effectively? Are we dealing with geometry, trigonometry, or another area of math?'}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': 'From our previous conversations, it appears you were looking for assistance with a math problem related to Pi, the mathematical constant. Can you provide more specific details about this problem so I can assist you better?'}, {'role': 'user', 'content': "As an AI, I don't have personal experiences or preferences, but I can provide information about apple pie or Pi (the mathematical constant). How can I assist you further?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your question about Pi. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 12:42:41,190 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 12:42:41,191 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 12:42:41,191 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 12:42:41,191 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 12:42:41,191 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 12:42:42,877 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 17:42:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'1510'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'78893'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'830ms'), (b'x-request-id', b'req_a6ce3f02067c447e0700b735b835b7b8'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd5442bee1d4408-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 12:42:42,877 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 12:42:42,878 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 12:42:42,878 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 12:42:42,878 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 12:42:42,878 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 12:42:42,878 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 12:42:42,879 [INFO] src.luna_functions: GPT response: As an artificial intelligence, I don't eat so I don't have personal experiences or preferences. However, I can provide information or even a recipe for apple pie! Now, how can I assist you with your inquiry about Pi, the mathematical constant?
2025-01-05 12:42:42,929 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:42:42,929 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:42:42,929 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:42:42,929 [INFO] src.luna_functions: Fetching last 100 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 12:42:42,945 [INFO] src.luna_functions: Fetched 30 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 12:42:42,946 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat so I don't have personal experiences or preferences. However, I can provide information or even a recipe for apple pie! Now, how can I assist you with your inquiry about Pi, the mathematical constant?"}, {'role': 'user', 'content': 'Understood, you need help with a problem related to Pi. Could you please specify the problem so I can assist you more effectively? Are we dealing with geometry, trigonometry, or another area of math?'}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': 'From our previous conversations, it appears you were looking for assistance with a math problem related to Pi, the mathematical constant. Can you provide more specific details about this problem so I can assist you better?'}, {'role': 'user', 'content': "As an AI, I don't have personal experiences or preferences, but I can provide information about apple pie or Pi (the mathematical constant). How can I assist you further?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your question about Pi. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'what do I need help with again'}]
2025-01-05 12:42:42,946 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat so I don't have personal experiences or preferences. However, I can provide information or even a recipe for apple pie! Now, how can I assist you with your inquiry about Pi, the mathematical constant?"}, {'role': 'user', 'content': 'Understood, you need help with a problem related to Pi. Could you please specify the problem so I can assist you more effectively? Are we dealing with geometry, trigonometry, or another area of math?'}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': 'From our previous conversations, it appears you were looking for assistance with a math problem related to Pi, the mathematical constant. Can you provide more specific details about this problem so I can assist you better?'}, {'role': 'user', 'content': "As an AI, I don't have personal experiences or preferences, but I can provide information about apple pie or Pi (the mathematical constant). How can I assist you further?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your question about Pi. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'what do I need help with again'}]
2025-01-05 12:42:42,967 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat so I don't have personal experiences or preferences. However, I can provide information or even a recipe for apple pie! Now, how can I assist you with your inquiry about Pi, the mathematical constant?"}, {'role': 'user', 'content': 'Understood, you need help with a problem related to Pi. Could you please specify the problem so I can assist you more effectively? Are we dealing with geometry, trigonometry, or another area of math?'}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': 'From our previous conversations, it appears you were looking for assistance with a math problem related to Pi, the mathematical constant. Can you provide more specific details about this problem so I can assist you better?'}, {'role': 'user', 'content': "As an AI, I don't have personal experiences or preferences, but I can provide information about apple pie or Pi (the mathematical constant). How can I assist you further?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your question about Pi. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': 'what do I need help with again'}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 12:42:42,968 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 12:42:42,968 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 12:42:42,968 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 12:42:42,968 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 12:42:42,968 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 12:42:46,333 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 17:42:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'2966'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'78837'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'872ms'), (b'x-request-id', b'req_0dcdba40ec76155bb1300388779a4979'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd544371af34408-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 12:42:46,334 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 12:42:46,335 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 12:42:46,335 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 12:42:46,336 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 12:42:46,336 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 12:42:46,336 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 12:42:46,337 [INFO] src.luna_functions: GPT response: From our previous discussions, it seems you were seeking assistance with a mathematical problem related to the constant Pi. Would you like to continue with that topic, or is there something new you need help with?
2025-01-05 12:42:46,367 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:42:46,374 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:42:46,374 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:42:46,374 [INFO] src.luna_functions: Fetching last 100 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 12:42:46,395 [INFO] src.luna_functions: Fetched 31 messages from room !byRaIjLPSRhKcNeUTu:localhost.
2025-01-05 12:42:46,395 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'From our previous discussions, it seems you were seeking assistance with a mathematical problem related to the constant Pi. Would you like to continue with that topic, or is there something new you need help with?'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat so I don't have personal experiences or preferences. However, I can provide information or even a recipe for apple pie! Now, how can I assist you with your inquiry about Pi, the mathematical constant?"}, {'role': 'user', 'content': 'Understood, you need help with a problem related to Pi. Could you please specify the problem so I can assist you more effectively? Are we dealing with geometry, trigonometry, or another area of math?'}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': 'From our previous conversations, it appears you were looking for assistance with a math problem related to Pi, the mathematical constant. Can you provide more specific details about this problem so I can assist you better?'}, {'role': 'user', 'content': "As an AI, I don't have personal experiences or preferences, but I can provide information about apple pie or Pi (the mathematical constant). How can I assist you further?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your question about Pi. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': "what's my name?"}]
2025-01-05 12:42:46,395 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'From our previous discussions, it seems you were seeking assistance with a mathematical problem related to the constant Pi. Would you like to continue with that topic, or is there something new you need help with?'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat so I don't have personal experiences or preferences. However, I can provide information or even a recipe for apple pie! Now, how can I assist you with your inquiry about Pi, the mathematical constant?"}, {'role': 'user', 'content': 'Understood, you need help with a problem related to Pi. Could you please specify the problem so I can assist you more effectively? Are we dealing with geometry, trigonometry, or another area of math?'}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': 'From our previous conversations, it appears you were looking for assistance with a math problem related to Pi, the mathematical constant. Can you provide more specific details about this problem so I can assist you better?'}, {'role': 'user', 'content': "As an AI, I don't have personal experiences or preferences, but I can provide information about apple pie or Pi (the mathematical constant). How can I assist you further?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your question about Pi. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': "what's my name?"}]
2025-01-05 12:42:46,416 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'From our previous discussions, it seems you were seeking assistance with a mathematical problem related to the constant Pi. Would you like to continue with that topic, or is there something new you need help with?'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat so I don't have personal experiences or preferences. However, I can provide information or even a recipe for apple pie! Now, how can I assist you with your inquiry about Pi, the mathematical constant?"}, {'role': 'user', 'content': 'Understood, you need help with a problem related to Pi. Could you please specify the problem so I can assist you more effectively? Are we dealing with geometry, trigonometry, or another area of math?'}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': 'From our previous conversations, it appears you were looking for assistance with a math problem related to Pi, the mathematical constant. Can you provide more specific details about this problem so I can assist you better?'}, {'role': 'user', 'content': "As an AI, I don't have personal experiences or preferences, but I can provide information about apple pie or Pi (the mathematical constant). How can I assist you further?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your question about Pi. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "Sure, I'd be happy to help you with your math problem. Could you please provide me with the details of the problem you're trying to solve?"}, {'role': 'user', 'content': "I'm sorry, but as an AI, I don't have the ability to access personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality."}, {'role': 'user', 'content': "what's my name?"}, {'role': 'user', 'content': 'Based on our previous interactions, you were looking to test the private channel. Do you need assistance with this or is there something else you need help with?'}, {'role': 'user', 'content': 'what do I need help with again'}, {'role': 'user', 'content': "As an artificial intelligence, I don't eat food. But I can certainly provide you with a great recipe for apple pie if you'd like!"}, {'role': 'user', 'content': 'not the kind of pi you eat but I love apple pie, you?'}, {'role': 'user', 'content': "Pi is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It's approximately 3.14159, but it's an irrational number, meaning it goes on indefinitely without repeating. How can I assist you further with Pi?"}, {'role': 'user', 'content': "It's about pi"}, {'role': 'user', 'content': "Of course, I'd be happy to help with your math problem. Could you please tell me what the problem is?"}, {'role': 'user', 'content': 'I need help figuring out a math problem'}, {'role': 'user', 'content': 'Nice to meet you, Steve. How can I assist you today?'}, {'role': 'user', 'content': "I'm steve"}, {'role': 'user', 'content': "I'm an artificial intelligence and don't have an account executive. However, I'm here to assist you. How can I help you further?"}, {'role': 'user', 'content': "what's your ae"}, {'role': 'user', 'content': "I'm glad to hear that! If you have any other questions or need further assistance with the private channel, feel free to ask."}, {'role': 'user', 'content': 'great'}, {'role': 'user', 'content': "I'm here and ready to assist. How may I help you with the test?"}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': "I'm here and ready to assist. How can we test the private channel according to your needs?"}, {'role': 'user', 'content': 'Hello! How can I assist you with the private channel?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test private channel'}, {'role': 'user', 'content': "what's my name?"}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 12:42:46,417 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 12:42:46,417 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 12:42:46,417 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 12:42:46,417 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 12:42:46,417 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 12:42:47,866 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 17:42:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'1168'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'78787'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'909ms'), (b'x-request-id', b'req_6deabde28cfbbed05448e72c24474dfb'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd5444caf5a4408-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 12:42:47,867 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 12:42:47,867 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 12:42:47,868 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 12:42:47,868 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 12:42:47,868 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 12:42:47,869 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 12:42:47,870 [INFO] src.luna_functions: GPT response: I'm sorry, but as an AI, I don't have access to personal data about individuals unless it has been shared with me in the course of our conversation. I'm designed to respect user privacy and confidentiality.
2025-01-05 12:42:47,895 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:42:47,895 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:42:47,895 [INFO] nio.client.base_client: New joined room !PmOiRDooqweqMsXyTN:localhost
2025-01-05 12:42:47,895 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type PowerLevelsEvent
2025-01-05 12:42:47,895 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomGuestAccessEvent
2025-01-05 12:42:47,895 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomHistoryVisibilityEvent
2025-01-05 12:42:47,896 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomJoinRulesEvent
2025-01-05 12:42:47,896 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomCreateEvent
2025-01-05 12:42:47,896 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:42:47,896 [INFO] src.luna_functions: Fetching last 100 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 12:42:47,913 [INFO] src.luna_functions: Fetched 17 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 12:42:47,913 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'hello'}, {'role': 'user', 'content': "I'm sorry, but the previous messages don't provide specific details about what you need help with. Could you please clarify or provide more information so I can assist you better?"}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'test'}]
2025-01-05 12:42:47,913 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'hello'}, {'role': 'user', 'content': "I'm sorry, but the previous messages don't provide specific details about what you need help with. Could you please clarify or provide more information so I can assist you better?"}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'test'}]
2025-01-05 12:42:47,921 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'hello'}, {'role': 'user', 'content': "I'm sorry, but the previous messages don't provide specific details about what you need help with. Could you please clarify or provide more information so I can assist you better?"}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'test'}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 12:42:47,921 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 12:42:47,922 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 12:42:47,922 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 12:42:47,922 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 12:42:47,922 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 12:42:49,709 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 17:42:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'1538'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79409'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'443ms'), (b'x-request-id', b'req_40238cf90b6b7941ee4e42121d660669'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd54455f9104408-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 12:42:49,709 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 12:42:49,710 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 12:42:49,710 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 12:42:49,710 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 12:42:49,710 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 12:42:49,710 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 12:42:49,711 [INFO] src.luna_functions: GPT response: I'm here and ready to assist you. Is there something specific you need help with?
2025-01-05 12:42:49,745 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:42:49,746 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:42:49,746 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:42:49,746 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:42:49,746 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:42:49,746 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:42:49,746 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:42:49,746 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:42:49,746 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:42:49,746 [INFO] src.luna_functions: Fetching last 100 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 12:42:49,759 [INFO] src.luna_functions: Fetched 18 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 12:42:49,759 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "I'm here and ready to assist you. Is there something specific you need help with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'hello'}, {'role': 'user', 'content': "I'm sorry, but the previous messages don't provide specific details about what you need help with. Could you please clarify or provide more information so I can assist you better?"}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'WHAT '}]
2025-01-05 12:42:49,759 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "I'm here and ready to assist you. Is there something specific you need help with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'hello'}, {'role': 'user', 'content': "I'm sorry, but the previous messages don't provide specific details about what you need help with. Could you please clarify or provide more information so I can assist you better?"}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'WHAT '}]
2025-01-05 12:42:49,774 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "I'm here and ready to assist you. Is there something specific you need help with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'hello'}, {'role': 'user', 'content': "I'm sorry, but the previous messages don't provide specific details about what you need help with. Could you please clarify or provide more information so I can assist you better?"}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'WHAT '}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 12:42:49,774 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 12:42:49,775 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 12:42:49,775 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 12:42:49,775 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 12:42:49,775 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 12:42:51,247 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 17:42:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'724'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79387'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'459ms'), (b'x-request-id', b'req_24b2a1894f7655ffafdf2bba8bcfb64b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd544619eee4408-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 12:42:51,249 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 12:42:51,249 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 12:42:51,250 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 12:42:51,250 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 12:42:51,251 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 12:42:51,251 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 12:42:51,252 [INFO] src.luna_functions: GPT response: I'm sorry for any confusion. Could you please provide more details or clarify what you need help with?
2025-01-05 12:42:51,294 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:42:51,294 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:42:51,295 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:42:51,295 [INFO] src.luna_functions: Fetching last 100 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 12:42:51,309 [INFO] src.luna_functions: Fetched 19 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 12:42:51,309 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "I'm sorry for any confusion. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': "I'm here and ready to assist you. Is there something specific you need help with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'hello'}, {'role': 'user', 'content': "I'm sorry, but the previous messages don't provide specific details about what you need help with. Could you please clarify or provide more information so I can assist you better?"}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'what did I want help with'}]
2025-01-05 12:42:51,309 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "I'm sorry for any confusion. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': "I'm here and ready to assist you. Is there something specific you need help with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'hello'}, {'role': 'user', 'content': "I'm sorry, but the previous messages don't provide specific details about what you need help with. Could you please clarify or provide more information so I can assist you better?"}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'what did I want help with'}]
2025-01-05 12:42:51,321 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "I'm sorry for any confusion. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': "I'm here and ready to assist you. Is there something specific you need help with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'hello'}, {'role': 'user', 'content': "I'm sorry, but the previous messages don't provide specific details about what you need help with. Could you please clarify or provide more information so I can assist you better?"}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'what did I want help with'}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 12:42:51,322 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 12:42:51,322 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 12:42:51,322 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 12:42:51,323 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 12:42:51,323 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 12:42:52,168 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 17:42:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'521'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79356'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'483ms'), (b'x-request-id', b'req_c9cf138344916b9ccfdd7eb8e3af076b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd5446b392a4408-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 12:42:52,169 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 12:42:52,169 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 12:42:52,170 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 12:42:52,170 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 12:42:52,170 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 12:42:52,171 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 12:42:52,172 [INFO] src.luna_functions: GPT response: I'm sorry, but I can't assist with that.
2025-01-05 12:42:52,202 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:42:52,203 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:42:52,232 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:42:52,232 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:42:52,237 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:42:52,237 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:42:52,237 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:42:52,237 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:42:52,237 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:42:52,237 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:42:52,237 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:42:52,237 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:42:52,237 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:42:52,237 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:42:52,237 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:42:52,237 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:42:52,237 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:42:52,237 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:42:52,256 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:42:52,256 [INFO] src.luna_functions: Fetching last 100 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 12:42:52,269 [INFO] src.luna_functions: Fetched 20 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 12:42:52,269 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "I'm sorry, but I can't assist with that."}, {'role': 'user', 'content': "I'm sorry for any confusion. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': "I'm here and ready to assist you. Is there something specific you need help with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'hello'}, {'role': 'user', 'content': "I'm sorry, but the previous messages don't provide specific details about what you need help with. Could you please clarify or provide more information so I can assist you better?"}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'hello'}]
2025-01-05 12:42:52,269 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "I'm sorry, but I can't assist with that."}, {'role': 'user', 'content': "I'm sorry for any confusion. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': "I'm here and ready to assist you. Is there something specific you need help with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'hello'}, {'role': 'user', 'content': "I'm sorry, but the previous messages don't provide specific details about what you need help with. Could you please clarify or provide more information so I can assist you better?"}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'hello'}]
2025-01-05 12:42:52,278 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': "I'm sorry, but I can't assist with that."}, {'role': 'user', 'content': "I'm sorry for any confusion. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': "I'm here and ready to assist you. Is there something specific you need help with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'hello'}, {'role': 'user', 'content': "I'm sorry, but the previous messages don't provide specific details about what you need help with. Could you please clarify or provide more information so I can assist you better?"}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 12:42:52,279 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 12:42:52,279 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 12:42:52,279 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 12:42:52,279 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 12:42:52,279 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 12:42:53,705 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 17:42:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'1169'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79350'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'487ms'), (b'x-request-id', b'req_a39f287e2de1711df761c6b1aa6e09ec'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd544714f8a4408-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 12:42:53,707 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 12:42:53,707 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 12:42:53,708 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 12:42:53,708 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 12:42:53,708 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 12:42:53,709 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 12:42:53,710 [INFO] src.luna_functions: GPT response: Hello! How can I assist you today?
2025-01-05 12:42:53,752 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:42:53,753 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:42:53,799 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:42:53,799 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:42:53,810 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:42:53,811 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:42:53,811 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:42:53,811 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:42:53,811 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:42:53,811 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:42:53,811 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:42:53,811 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:42:53,811 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:42:53,811 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:42:53,811 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:42:53,811 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:42:53,811 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:42:53,811 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:42:53,811 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:42:53,811 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:43:13,955 [INFO] src.console_functions: Console received 'check-limit' command. Checking for rate-limit...
2025-01-05 12:43:13,956 [ERROR] src.luna_functions: check_rate_limit encountered an error: 'AsyncClient' object has no attribute 'session'
Traceback (most recent call last):
  File "/Users/evanrobinson/Documents/Luna2/luna/src/luna_functions.py", line 253, in check_rate_limit
    async with DIRECTOR_CLIENT.session.get(url, headers=headers) as resp:
               ^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'AsyncClient' object has no attribute 'session'
2025-01-05 12:45:45,400 [INFO] src.console_functions: Console received 'restart' command; restarting now.
2025-01-05 12:45:46,070 [DEBUG] __main__: Added file handler to root logger. Logging to 'server.log' at DEBUG level.
2025-01-05 12:45:46,070 [DEBUG] __main__: Exiting configure_logging function.
2025-01-05 12:45:46,070 [DEBUG] __main__: Logging configuration complete.
2025-01-05 12:45:46,070 [DEBUG] __main__: Creating a new asyncio event loop.
2025-01-05 12:45:46,071 [DEBUG] asyncio: Using selector: KqueueSelector
2025-01-05 12:45:46,071 [DEBUG] __main__: Set this new loop as the default event loop for the current thread.
2025-01-05 12:45:46,071 [DEBUG] __main__: Stored reference to the new loop in MAIN_LOOP.
2025-01-05 12:45:46,071 [DEBUG] __main__: Entering start_console_thread function.
2025-01-05 12:45:46,071 [INFO] __main__: Console thread started successfully.
2025-01-05 12:45:46,071 [DEBUG] __main__: Exiting start_console_thread function.
2025-01-05 12:45:46,071 [DEBUG] __main__: Console thread has been initiated. Returning to main thread.
2025-01-05 12:45:46,071 [INFO] __main__: Starting main_logic coroutine.
2025-01-05 12:45:46,071 [DEBUG] __main__: Entering main_logic function...
2025-01-05 12:45:46,071 [DEBUG] __main__: Attempting to load or log in the client.
2025-01-05 12:45:46,172 [DEBUG] src.luna_functions: Found director_token.json, attempting token-based login.
2025-01-05 12:45:46,173 [DEBUG] src.luna_functions: Loading client with saved token credentials.
2025-01-05 12:45:46,173 [INFO] src.luna_functions: Using saved token for user @luna:localhost.
2025-01-05 12:45:46,173 [DEBUG] __main__: Client obtained. Storing reference to DIRECTOR_CLIENT in src.luna_functions.
2025-01-05 12:45:46,173 [DEBUG] __main__: Callbacks registered successfully.
2025-01-05 12:45:46,173 [DEBUG] __main__: Starting sync_forever loop. Awaiting new events with timeout=30000.
2025-01-05 12:45:46,216 [INFO] nio.client.base_client: New joined room !byRaIjLPSRhKcNeUTu:localhost
2025-01-05 12:45:46,216 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomTopicEvent
2025-01-05 12:45:46,216 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomNameEvent
2025-01-05 12:45:46,216 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomAliasEvent
2025-01-05 12:45:46,216 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomJoinRulesEvent
2025-01-05 12:45:46,216 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type PowerLevelsEvent
2025-01-05 12:45:46,217 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomCreateEvent
2025-01-05 12:45:46,217 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomHistoryVisibilityEvent
2025-01-05 12:45:46,217 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:45:46,217 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:45:46,217 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:45:46,217 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:45:46,217 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:45:46,217 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:45:46,217 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:45:46,217 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:45:46,217 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:45:46,217 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:45:46,217 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:45:46,217 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:45:46,217 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:45:46,217 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:45:46,217 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:45:46,217 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:45:46,217 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:45:46,217 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:45:46,217 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:45:46,217 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:45:46,217 [INFO] nio.client.base_client: New joined room !PmOiRDooqweqMsXyTN:localhost
2025-01-05 12:45:46,217 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomHistoryVisibilityEvent
2025-01-05 12:45:46,217 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomJoinRulesEvent
2025-01-05 12:45:46,217 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type PowerLevelsEvent
2025-01-05 12:45:46,217 [INFO] nio.rooms: Changing power level for user @luna:localhost from 0 to 100
2025-01-05 12:45:46,217 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomCreateEvent
2025-01-05 12:45:46,217 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomGuestAccessEvent
2025-01-05 12:45:46,217 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:45:46,217 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:45:46,217 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:45:46,217 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:45:46,217 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:45:46,217 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:45:46,217 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:45:46,217 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:45:46,217 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:45:46,217 [INFO] src.luna_functions: Fetching last 100 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 12:45:46,226 [INFO] src.luna_functions: Fetched 21 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 12:45:46,226 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but I can't assist with that."}, {'role': 'user', 'content': "I'm sorry for any confusion. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': "I'm here and ready to assist you. Is there something specific you need help with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'hello'}, {'role': 'user', 'content': "I'm sorry, but the previous messages don't provide specific details about what you need help with. Could you please clarify or provide more information so I can assist you better?"}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'hello'}]
2025-01-05 12:45:46,226 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but I can't assist with that."}, {'role': 'user', 'content': "I'm sorry for any confusion. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': "I'm here and ready to assist you. Is there something specific you need help with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'hello'}, {'role': 'user', 'content': "I'm sorry, but the previous messages don't provide specific details about what you need help with. Could you please clarify or provide more information so I can assist you better?"}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'hello'}]
2025-01-05 12:45:46,269 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but I can't assist with that."}, {'role': 'user', 'content': "I'm sorry for any confusion. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': "I'm here and ready to assist you. Is there something specific you need help with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'hello'}, {'role': 'user', 'content': "I'm sorry, but the previous messages don't provide specific details about what you need help with. Could you please clarify or provide more information so I can assist you better?"}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 12:45:46,273 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-01-05 12:45:46,679 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10c968440>
2025-01-05 12:45:46,679 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x10c8655b0> server_hostname='api.openai.com' timeout=5.0
2025-01-05 12:45:46,757 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10c8d25d0>
2025-01-05 12:45:46,757 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 12:45:46,758 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 12:45:46,758 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 12:45:46,758 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 12:45:46,758 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 12:45:48,464 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 17:45:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'548'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79340'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'495ms'), (b'x-request-id', b'req_3c89f79d6aa895122d6f376fa7ec780c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=b7pm7nork0Wj.5kny0kfBnNHpKSR89BnUTuCQj2Q7L0-1736099147-1.0.1.1-zp7_JHTR9P6XTTvMRy6vdEV75db70dpnPmwX2uMudmAEnCrcjvP9MAtfwhXGeiTPmGTowIHa2xliRUqwQ3a17Q; path=/; expires=Sun, 05-Jan-25 18:15:47 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=szQ4yTdQnJz4wlpdb0HblcpHpq4uiM6IIw1Cxz0hY.c-1736099147981-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd548b41b1f439c-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 12:45:48,466 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 12:45:48,467 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 12:45:48,467 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 12:45:48,468 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 12:45:48,468 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 12:45:48,468 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 12:45:48,474 [INFO] src.luna_functions: GPT response: Hello! How can I assist you today?
2025-01-05 12:45:48,515 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:45:48,516 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:45:48,516 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:45:48,516 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:45:48,516 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:45:48,516 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:45:48,516 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:45:48,516 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:45:48,516 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:45:48,516 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:45:48,526 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:45:48,526 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:45:49,609 [DEBUG] src.console_functions: Showing help to user.
2025-01-05 12:46:01,884 [INFO] src.console_functions: Console received 'check-limit' command. Checking for rate-limit...
2025-01-05 12:46:01,885 [ERROR] src.luna_functions: check_rate_limit encountered an error: 'AsyncClient' object has no attribute 'api'
Traceback (most recent call last):
  File "/Users/evanrobinson/Documents/Luna2/luna/src/luna_functions.py", line 244, in check_rate_limit
    response = await DIRECTOR_CLIENT.api.request(
                     ^^^^^^^^^^^^^^^^^^^
AttributeError: 'AsyncClient' object has no attribute 'api'
2025-01-05 12:48:18,453 [INFO] src.console_functions: Console received 'restart' command; restarting now.
2025-01-05 12:48:19,032 [DEBUG] __main__: Added file handler to root logger. Logging to 'server.log' at DEBUG level.
2025-01-05 12:48:19,032 [DEBUG] __main__: Exiting configure_logging function.
2025-01-05 12:48:19,032 [DEBUG] __main__: Logging configuration complete.
2025-01-05 12:48:19,032 [DEBUG] __main__: Creating a new asyncio event loop.
2025-01-05 12:48:19,032 [DEBUG] asyncio: Using selector: KqueueSelector
2025-01-05 12:48:19,032 [DEBUG] __main__: Set this new loop as the default event loop for the current thread.
2025-01-05 12:48:19,032 [DEBUG] __main__: Stored reference to the new loop in MAIN_LOOP.
2025-01-05 12:48:19,033 [DEBUG] __main__: Entering start_console_thread function.
2025-01-05 12:48:19,033 [INFO] __main__: Console thread started successfully.
2025-01-05 12:48:19,033 [DEBUG] __main__: Exiting start_console_thread function.
2025-01-05 12:48:19,033 [DEBUG] __main__: Console thread has been initiated. Returning to main thread.
2025-01-05 12:48:19,033 [INFO] __main__: Starting main_logic coroutine.
2025-01-05 12:48:19,033 [DEBUG] __main__: Entering main_logic function...
2025-01-05 12:48:19,033 [DEBUG] __main__: Attempting to load or log in the client.
2025-01-05 12:48:19,134 [DEBUG] src.luna_functions: Found director_token.json, attempting token-based login.
2025-01-05 12:48:19,134 [DEBUG] src.luna_functions: Loading client with saved token credentials.
2025-01-05 12:48:19,134 [INFO] src.luna_functions: Using saved token for user @luna:localhost.
2025-01-05 12:48:19,134 [DEBUG] __main__: Client obtained. Storing reference to DIRECTOR_CLIENT in src.luna_functions.
2025-01-05 12:48:19,134 [DEBUG] __main__: Callbacks registered successfully.
2025-01-05 12:48:19,134 [DEBUG] __main__: Starting sync_forever loop. Awaiting new events with timeout=30000.
2025-01-05 12:48:19,163 [INFO] nio.client.base_client: New joined room !byRaIjLPSRhKcNeUTu:localhost
2025-01-05 12:48:19,164 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomTopicEvent
2025-01-05 12:48:19,164 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomNameEvent
2025-01-05 12:48:19,164 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomAliasEvent
2025-01-05 12:48:19,164 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomJoinRulesEvent
2025-01-05 12:48:19,164 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type PowerLevelsEvent
2025-01-05 12:48:19,164 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomCreateEvent
2025-01-05 12:48:19,164 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomHistoryVisibilityEvent
2025-01-05 12:48:19,164 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:48:19,164 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:19,164 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:48:19,164 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:19,164 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:48:19,164 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:19,164 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:48:19,164 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:19,164 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:48:19,164 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:19,164 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:48:19,164 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:19,164 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:48:19,164 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:19,164 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:48:19,164 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:19,164 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:48:19,164 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:19,164 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:48:19,164 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:19,164 [INFO] nio.client.base_client: New joined room !PmOiRDooqweqMsXyTN:localhost
2025-01-05 12:48:19,164 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomHistoryVisibilityEvent
2025-01-05 12:48:19,164 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomJoinRulesEvent
2025-01-05 12:48:19,164 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type PowerLevelsEvent
2025-01-05 12:48:19,164 [INFO] nio.rooms: Changing power level for user @luna:localhost from 0 to 100
2025-01-05 12:48:19,164 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomCreateEvent
2025-01-05 12:48:19,164 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomGuestAccessEvent
2025-01-05 12:48:19,164 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:48:19,164 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:19,164 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:48:19,164 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:19,164 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:48:19,164 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:19,164 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:48:19,164 [INFO] src.luna_functions: Fetching last 100 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 12:48:19,175 [INFO] src.luna_functions: Fetched 22 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 12:48:19,176 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but I can't assist with that."}, {'role': 'user', 'content': "I'm sorry for any confusion. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': "I'm here and ready to assist you. Is there something specific you need help with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'hello'}, {'role': 'user', 'content': "I'm sorry, but the previous messages don't provide specific details about what you need help with. Could you please clarify or provide more information so I can assist you better?"}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'hello'}]
2025-01-05 12:48:19,176 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but I can't assist with that."}, {'role': 'user', 'content': "I'm sorry for any confusion. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': "I'm here and ready to assist you. Is there something specific you need help with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'hello'}, {'role': 'user', 'content': "I'm sorry, but the previous messages don't provide specific details about what you need help with. Could you please clarify or provide more information so I can assist you better?"}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'hello'}]
2025-01-05 12:48:19,205 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but I can't assist with that."}, {'role': 'user', 'content': "I'm sorry for any confusion. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': "I'm here and ready to assist you. Is there something specific you need help with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'hello'}, {'role': 'user', 'content': "I'm sorry, but the previous messages don't provide specific details about what you need help with. Could you please clarify or provide more information so I can assist you better?"}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 12:48:19,208 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-01-05 12:48:19,368 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107a6c440>
2025-01-05 12:48:19,369 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x1078695b0> server_hostname='api.openai.com' timeout=5.0
2025-01-05 12:48:19,452 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1078d65d0>
2025-01-05 12:48:19,452 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 12:48:19,549 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 12:48:19,549 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 12:48:19,549 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 12:48:19,549 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 12:48:21,239 [INFO] src.console_functions: Console received 'check-limit' command. Checking for rate-limit...
2025-01-05 12:48:21,240 [ERROR] src.luna_functions: check_rate_limit encountered an error: AsyncClient.sync() got an unexpected keyword argument 'timeout_ms'. Did you mean 'timeout'?
Traceback (most recent call last):
  File "/Users/evanrobinson/Documents/Luna2/luna/src/luna_functions.py", line 242, in check_rate_limit
    response = await DIRECTOR_CLIENT.sync(timeout_ms=1000)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/evanrobinson/Documents/Luna2/luna/.venv/lib/python3.13/site-packages/nio/client/base_client.py", line 116, in wrapper
    return await func(self, *args, **kwargs)
                 ~~~~^^^^^^^^^^^^^^^^^^^^^^^
TypeError: AsyncClient.sync() got an unexpected keyword argument 'timeout_ms'. Did you mean 'timeout'?
2025-01-05 12:48:23,464 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 17:48:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'3511'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79331'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'501ms'), (b'x-request-id', b'req_dedee1e7b31e67cac343c55d21bec85b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=i7jvhRmuRzfdUVOT3mGzGucCfzvbcg59SleZqqUfnWY-1736099303-1.0.1.1-7eWXlftQNPjUfnFm.GnwhuU5g6RXhWy2tbOZxmqWD_WYPfBK1JEB3DE20uQbDQJFVX6FrN4lJnSRaA3oRzWy5w; path=/; expires=Sun, 05-Jan-25 18:18:23 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=tIina8wzSNAQHKw3UZmauBZLGxollG10_IYZVxJU2.w-1736099303226-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd54c6eac2f7ce4-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 12:48:23,466 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 12:48:23,466 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 12:48:23,466 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 12:48:23,466 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 12:48:23,466 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 12:48:23,467 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 12:48:23,471 [INFO] src.luna_functions: GPT response: Hello! How can I assist you today?
2025-01-05 12:48:23,517 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:48:23,518 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:23,518 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:48:23,518 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:23,518 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:48:23,518 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:23,518 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:48:23,518 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:23,518 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:48:23,518 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:23,519 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:48:23,519 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:23,528 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:48:23,528 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:34,937 [INFO] src.console_functions: Console received 'restart' command; restarting now.
2025-01-05 12:48:35,548 [DEBUG] __main__: Added file handler to root logger. Logging to 'server.log' at DEBUG level.
2025-01-05 12:48:35,548 [DEBUG] __main__: Exiting configure_logging function.
2025-01-05 12:48:35,548 [DEBUG] __main__: Logging configuration complete.
2025-01-05 12:48:35,548 [DEBUG] __main__: Creating a new asyncio event loop.
2025-01-05 12:48:35,548 [DEBUG] asyncio: Using selector: KqueueSelector
2025-01-05 12:48:35,548 [DEBUG] __main__: Set this new loop as the default event loop for the current thread.
2025-01-05 12:48:35,548 [DEBUG] __main__: Stored reference to the new loop in MAIN_LOOP.
2025-01-05 12:48:35,548 [DEBUG] __main__: Entering start_console_thread function.
2025-01-05 12:48:35,548 [INFO] __main__: Console thread started successfully.
2025-01-05 12:48:35,548 [DEBUG] __main__: Exiting start_console_thread function.
2025-01-05 12:48:35,548 [DEBUG] __main__: Console thread has been initiated. Returning to main thread.
2025-01-05 12:48:35,548 [INFO] __main__: Starting main_logic coroutine.
2025-01-05 12:48:35,548 [DEBUG] __main__: Entering main_logic function...
2025-01-05 12:48:35,548 [DEBUG] __main__: Attempting to load or log in the client.
2025-01-05 12:48:35,649 [DEBUG] src.luna_functions: Found director_token.json, attempting token-based login.
2025-01-05 12:48:35,650 [DEBUG] src.luna_functions: Loading client with saved token credentials.
2025-01-05 12:48:35,650 [INFO] src.luna_functions: Using saved token for user @luna:localhost.
2025-01-05 12:48:35,650 [DEBUG] __main__: Client obtained. Storing reference to DIRECTOR_CLIENT in src.luna_functions.
2025-01-05 12:48:35,650 [DEBUG] __main__: Callbacks registered successfully.
2025-01-05 12:48:35,650 [DEBUG] __main__: Starting sync_forever loop. Awaiting new events with timeout=30000.
2025-01-05 12:48:35,666 [INFO] nio.client.base_client: New joined room !byRaIjLPSRhKcNeUTu:localhost
2025-01-05 12:48:35,667 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomTopicEvent
2025-01-05 12:48:35,667 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomNameEvent
2025-01-05 12:48:35,667 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomAliasEvent
2025-01-05 12:48:35,667 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomJoinRulesEvent
2025-01-05 12:48:35,667 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type PowerLevelsEvent
2025-01-05 12:48:35,667 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomCreateEvent
2025-01-05 12:48:35,667 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomHistoryVisibilityEvent
2025-01-05 12:48:35,667 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:48:35,667 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:35,667 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:48:35,667 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:35,667 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:48:35,667 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:35,667 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:48:35,667 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:35,667 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:48:35,667 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:35,667 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:48:35,667 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:35,667 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:48:35,667 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:35,667 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:48:35,667 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:35,667 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:48:35,667 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:35,667 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 12:48:35,667 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:35,667 [INFO] nio.client.base_client: New joined room !PmOiRDooqweqMsXyTN:localhost
2025-01-05 12:48:35,667 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomHistoryVisibilityEvent
2025-01-05 12:48:35,667 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomJoinRulesEvent
2025-01-05 12:48:35,667 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type PowerLevelsEvent
2025-01-05 12:48:35,667 [INFO] nio.rooms: Changing power level for user @luna:localhost from 0 to 100
2025-01-05 12:48:35,667 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomCreateEvent
2025-01-05 12:48:35,667 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomGuestAccessEvent
2025-01-05 12:48:35,667 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:48:35,667 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:35,667 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:48:35,667 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:35,667 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:48:35,667 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:35,667 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:48:35,667 [INFO] src.luna_functions: Fetching last 100 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 12:48:35,694 [INFO] src.luna_functions: Fetched 23 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 12:48:35,694 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but I can't assist with that."}, {'role': 'user', 'content': "I'm sorry for any confusion. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': "I'm here and ready to assist you. Is there something specific you need help with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'hello'}, {'role': 'user', 'content': "I'm sorry, but the previous messages don't provide specific details about what you need help with. Could you please clarify or provide more information so I can assist you better?"}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'hello'}]
2025-01-05 12:48:35,694 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but I can't assist with that."}, {'role': 'user', 'content': "I'm sorry for any confusion. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': "I'm here and ready to assist you. Is there something specific you need help with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'hello'}, {'role': 'user', 'content': "I'm sorry, but the previous messages don't provide specific details about what you need help with. Could you please clarify or provide more information so I can assist you better?"}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'hello'}]
2025-01-05 12:48:35,724 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but I can't assist with that."}, {'role': 'user', 'content': "I'm sorry for any confusion. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': "I'm here and ready to assist you. Is there something specific you need help with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'hello'}, {'role': 'user', 'content': "I'm sorry, but the previous messages don't provide specific details about what you need help with. Could you please clarify or provide more information so I can assist you better?"}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 12:48:35,729 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-01-05 12:48:35,815 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10432c440>
2025-01-05 12:48:35,815 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x1042255b0> server_hostname='api.openai.com' timeout=5.0
2025-01-05 12:48:35,897 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1042965d0>
2025-01-05 12:48:35,897 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 12:48:35,898 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 12:48:35,898 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 12:48:35,898 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 12:48:35,898 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 12:48:37,468 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 17:48:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'926'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79321'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'509ms'), (b'x-request-id', b'req_f804e25fcfbb1884768548630bd3000a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=YNqfgsbw4bCZ_Yy0wYq5OwnXyEbkoNZZbC0yybtuVmQ-1736099316-1.0.1.1-WJZSHmFKc1uWRMhV4XWuaexLTSOLAR0Jusmv.RfgvVi2N.IhdjRIQEJ5dUK_FqNXTwETfQ2VypCkEadxfJ7U2g; path=/; expires=Sun, 05-Jan-25 18:18:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=QZsTITDLRplXFSTgb7U9qNrgVfSiIqkNywyi7Vdw4Ms-1736099316966-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd54cd4ce290f9d-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 12:48:37,470 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 12:48:37,470 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 12:48:37,470 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 12:48:37,470 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 12:48:37,471 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 12:48:37,471 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 12:48:37,475 [INFO] src.luna_functions: GPT response: Hello! How can I assist you today?
2025-01-05 12:48:37,516 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:48:37,516 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:37,516 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:48:37,516 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:37,516 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:48:37,516 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:37,516 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:48:37,516 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:37,516 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:48:37,516 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:37,516 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:48:37,516 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:37,520 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:48:37,520 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:37,523 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 12:48:37,523 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 12:48:40,706 [INFO] src.console_functions: Console screen cleared.
2025-01-05 12:48:42,512 [INFO] src.console_functions: Console received 'check-limit' command. Checking for rate-limit...
2025-01-05 13:55:42,025 [INFO] src.console_functions: Console screen cleared.
2025-01-05 14:02:23,585 [INFO] src.console_functions: Console received 'restart' command; restarting now.
2025-01-05 14:02:24,325 [DEBUG] __main__: Added file handler to root logger. Logging to 'server.log' at DEBUG level.
2025-01-05 14:02:24,325 [DEBUG] __main__: Exiting configure_logging function.
2025-01-05 14:02:24,325 [DEBUG] __main__: Logging configuration complete.
2025-01-05 14:02:24,325 [DEBUG] __main__: Creating a new asyncio event loop.
2025-01-05 14:02:24,326 [DEBUG] asyncio: Using selector: KqueueSelector
2025-01-05 14:02:24,326 [DEBUG] __main__: Set this new loop as the default event loop for the current thread.
2025-01-05 14:02:24,326 [DEBUG] __main__: Stored reference to the new loop in MAIN_LOOP.
2025-01-05 14:02:24,326 [DEBUG] __main__: Entering start_console_thread function.
2025-01-05 14:02:24,326 [INFO] __main__: Console thread started successfully.
2025-01-05 14:02:24,326 [DEBUG] __main__: Exiting start_console_thread function.
2025-01-05 14:02:24,326 [DEBUG] __main__: Console thread has been initiated. Returning to main thread.
2025-01-05 14:02:24,326 [INFO] __main__: Starting main_logic coroutine.
2025-01-05 14:02:24,326 [DEBUG] __main__: Entering main_logic function...
2025-01-05 14:02:24,326 [DEBUG] __main__: Attempting to load or log in the client.
2025-01-05 14:02:24,427 [DEBUG] src.luna_functions: Found director_token.json, attempting token-based login.
2025-01-05 14:02:24,428 [DEBUG] src.luna_functions: Loading client with saved token credentials.
2025-01-05 14:02:24,428 [INFO] src.luna_functions: Using saved token for user @luna:localhost.
2025-01-05 14:02:24,428 [DEBUG] __main__: Client obtained. Storing reference to DIRECTOR_CLIENT in src.luna_functions.
2025-01-05 14:02:24,428 [DEBUG] __main__: Callbacks registered successfully.
2025-01-05 14:02:24,428 [DEBUG] __main__: Starting sync_forever loop. Awaiting new events with timeout=30000.
2025-01-05 14:02:24,496 [INFO] nio.client.base_client: New joined room !byRaIjLPSRhKcNeUTu:localhost
2025-01-05 14:02:24,496 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomTopicEvent
2025-01-05 14:02:24,497 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomNameEvent
2025-01-05 14:02:24,497 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomAliasEvent
2025-01-05 14:02:24,497 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomJoinRulesEvent
2025-01-05 14:02:24,497 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type PowerLevelsEvent
2025-01-05 14:02:24,497 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomCreateEvent
2025-01-05 14:02:24,497 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomHistoryVisibilityEvent
2025-01-05 14:02:24,497 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 14:02:24,497 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 14:02:24,497 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 14:02:24,497 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 14:02:24,497 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 14:02:24,497 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 14:02:24,497 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 14:02:24,497 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 14:02:24,497 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 14:02:24,497 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 14:02:24,497 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 14:02:24,497 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 14:02:24,497 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 14:02:24,497 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 14:02:24,497 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 14:02:24,497 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 14:02:24,497 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 14:02:24,497 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 14:02:24,497 [INFO] nio.rooms: Room !byRaIjLPSRhKcNeUTu:localhost handling event of type RoomMessageText
2025-01-05 14:02:24,497 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 14:02:24,497 [INFO] nio.client.base_client: New joined room !PmOiRDooqweqMsXyTN:localhost
2025-01-05 14:02:24,497 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomHistoryVisibilityEvent
2025-01-05 14:02:24,497 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomJoinRulesEvent
2025-01-05 14:02:24,497 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type PowerLevelsEvent
2025-01-05 14:02:24,497 [INFO] nio.rooms: Changing power level for user @luna:localhost from 0 to 100
2025-01-05 14:02:24,497 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomCreateEvent
2025-01-05 14:02:24,497 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomGuestAccessEvent
2025-01-05 14:02:24,497 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 14:02:24,497 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 14:02:24,497 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 14:02:24,497 [INFO] src.luna_functions: Fetching last 100 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 14:02:24,510 [INFO] src.luna_functions: Fetched 24 messages from room !PmOiRDooqweqMsXyTN:localhost.
2025-01-05 14:02:24,510 [DEBUG] src.luna_functions: Formatted context for GPT: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but I can't assist with that."}, {'role': 'user', 'content': "I'm sorry for any confusion. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': "I'm here and ready to assist you. Is there something specific you need help with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'hello'}, {'role': 'user', 'content': "I'm sorry, but the previous messages don't provide specific details about what you need help with. Could you please clarify or provide more information so I can assist you better?"}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'hello'}]
2025-01-05 14:02:24,510 [DEBUG] src.ai_functions: get_gpt_response called with context: [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but I can't assist with that."}, {'role': 'user', 'content': "I'm sorry for any confusion. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': "I'm here and ready to assist you. Is there something specific you need help with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'hello'}, {'role': 'user', 'content': "I'm sorry, but the previous messages don't provide specific details about what you need help with. Could you please clarify or provide more information so I can assist you better?"}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'hello'}]
2025-01-05 14:02:24,583 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant. The provided context array includes messages from an ongoing conversation. Treat this context as fair use and consider it an essential part of the conversation. Your responses should build on this context coherently.'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but I can't assist with that."}, {'role': 'user', 'content': "I'm sorry for any confusion. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': "I'm here and ready to assist you. Is there something specific you need help with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'hello'}, {'role': 'user', 'content': "I'm sorry, but the previous messages don't provide specific details about what you need help with. Could you please clarify or provide more information so I can assist you better?"}, {'role': 'user', 'content': "I'm sorry, but your previous messages are a bit unclear. Could you please specify what you need assistance with?"}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': "I'm sorry, but your previous messages do not indicate any specific request for help. Could you please provide more details or clarify what you need help with?"}, {'role': 'user', 'content': 'what did I want help with'}, {'role': 'user', 'content': "I'm here to help! Could you please provide more details or clarify your request?"}, {'role': 'user', 'content': 'WHAT '}, {'role': 'user', 'content': 'Hello! How can I assist you further?'}, {'role': 'user', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': "I'm sorry, but that's not correct. The value of Pi (π) is approximately 3.14159."}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'test'}, {'role': 'user', 'content': 'Pi is 5.14159'}, {'role': 'user', 'content': 'hi'}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-4', 'max_tokens': 300, 'temperature': 0.7}}
2025-01-05 14:02:24,588 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-01-05 14:02:24,749 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1082402f0>
2025-01-05 14:02:24,749 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x10813d5b0> server_hostname='api.openai.com' timeout=5.0
2025-01-05 14:02:24,935 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1081ae5d0>
2025-01-05 14:02:24,936 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-01-05 14:02:24,937 [DEBUG] httpcore.http11: send_request_headers.complete
2025-01-05 14:02:24,937 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-01-05 14:02:24,937 [DEBUG] httpcore.http11: send_request_body.complete
2025-01-05 14:02:24,937 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-01-05 14:02:26,519 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 05 Jan 2025 19:02:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yzbp3micnvwwjimbcblinra3'), (b'openai-processing-ms', b'1073'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79312'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'516ms'), (b'x-request-id', b'req_88a8d6846fe6d71acfc6bb840077e779'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=qJoW86y14wzyQTSiVbKFBODWI1Wb99iHOpnKxPGMM.U-1736103746-1.0.1.1-AV9zHlmn6kbwjFguV8k4sE9_llUlIcdju80cyB5cRQaCMRR8SpoUOCUiGbev88Pf6aF_4pqDrt0r_8D8mOwWqg; path=/; expires=Sun, 05-Jan-25 19:32:26 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=EuC85r2CtLJw5c51Wnqdz23stlGcXarzAZR.eGNrUTY-1736103746404-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8fd5b8f6d80b15c7-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-01-05 14:02:26,521 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-05 14:02:26,521 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-01-05 14:02:26,522 [DEBUG] httpcore.http11: receive_response_body.complete
2025-01-05 14:02:26,522 [DEBUG] httpcore.http11: response_closed.started
2025-01-05 14:02:26,522 [DEBUG] httpcore.http11: response_closed.complete
2025-01-05 14:02:26,523 [DEBUG] openai._base_client: HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2025-01-05 14:02:26,528 [INFO] src.luna_functions: GPT response: Hello! How can I assist you today?
2025-01-05 14:02:26,542 [INFO] src.console_functions: Console received 'check-limit' command. Blocking until result is returned...
2025-01-05 14:02:26,569 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 14:02:26,569 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 14:02:26,569 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 14:02:26,569 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 14:02:26,569 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 14:02:26,569 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 14:02:26,569 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 14:02:26,569 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 14:02:26,569 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 14:02:26,569 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 14:02:26,569 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 14:02:26,569 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 14:02:26,569 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 14:02:26,570 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 14:02:26,570 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 14:02:26,570 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 14:02:26,574 [INFO] nio.rooms: Room !PmOiRDooqweqMsXyTN:localhost handling event of type RoomMessageText
2025-01-05 14:02:26,574 [DEBUG] src.luna_functions: Ignoring my own message.
2025-01-05 15:37:49,981 [WARNING] __main__: KeyboardInterrupt received. Shutting down Director.
2025-01-05 15:37:49,982 [DEBUG] __main__: Preparing to close the event loop.
2025-01-05 15:37:49,983 [INFO] __main__: Event loop closed. Exiting main function.
